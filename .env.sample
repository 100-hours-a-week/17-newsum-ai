# .env.sample - ComicGenerator 프로젝트 환경 변수 설정 예시
# 이 파일을 .env 로 복사한 후, 실제 환경에 맞게 값을 수정하여 사용하세요.
# 주석(#)으로 시작하는 줄은 무시됩니다.

# --- 핵심 설정 ---
PROJECT_NAME=ComicGenerator
DEBUG=False # 개발 모드 활성화 여부 (True/False)

# --- LLM API 설정 ---
# 사용하려는 LLM API 엔드포인트 (예: OpenAI 호환 로컬 서버, 클라우드 API 등)
LLM_API_ENDPOINT=http://localhost:8000/v1 # 또는 https://api.openai.com/v1 등
LLM_API_KEY=your_llm_api_key_here # LLM API 키 (필요한 경우)
LLM_API_TIMEOUT=60 # LLM API 호출 타임아웃 (초)
# LLM_API_RETRIES=3 # (settings.py 내 기본값 사용)

# --- 기본 모델 설정 ---
DEFAULT_LLM_MODEL=gpt-4o-mini # 기본으로 사용할 LLM 모델 이름
DEFAULT_IMAGE_MODEL=dall-e-3 # 기본으로 사용할 이미지 생성 모델 이름

# --- 이미지 생성 서버 API 설정 (예: Stable Diffusion WebUI 등) ---
IMAGE_SERVER_URL=http://127.0.0.1:7860 # 이미지 생성 서버 주소 (로컬 Stable Diffusion WebUI 예시)
IMAGE_SERVER_API_TOKEN= # 이미지 생성 서버 인증 토큰 (필요한 경우)
# IMAGE_STORAGE_PATH= # (settings.py 내 기본값 사용 - storage/images)

# --- Redis 캐시/DB 설정 ---
REDIS_HOST=localhost # Redis 서버 호스트 이름
REDIS_PORT=6379 # Redis 서버 포트
REDIS_DB=0 # 사용할 Redis 데이터베이스 번호
REDIS_PASSWORD= # Redis 비밀번호 (없으면 비워두세요)
# TOPIC_ANALYZER_CACHE_TTL=1800 # (settings.py 내 기본값 사용 - 30분)

# --- LangSmith 설정 (선택 사항) ---
# LangSmith 추적을 사용하려면 아래 값들을 설정하세요.
LANGCHAIN_API_KEY=your_langchain_api_key_here # LangSmith API 키
LANGCHAIN_PROJECT=ComicGenerator-Project # LangSmith 프로젝트 이름
# LANGCHAIN_ENDPOINT=https://api.smith.langchain.com # LangSmith 엔드포인트 (기본값, 온프레미스 등 사용 시 수정)
# LANGCHAIN_TRACING_V2=true # LangSmith 추적 활성화 (이 변수를 직접 설정하는 것을 권장)

# --- AWS S3 스토리지 설정 (선택 사항) ---
# 생성된 이미지 등을 S3에 저장하려면 설정합니다.
S3_BUCKET_NAME=your-s3-bucket-name # 사용할 S3 버킷 이름
AWS_REGION=ap-northeast-2 # 사용할 AWS 리전 (예: 서울)
# AWS 자격 증명은 ~/.aws/credentials 또는 EC2 인스턴스 프로파일 등을 통해 관리하는 것이 일반적입니다.

# --- 검색 API 및 도구 설정 ---
# Google Custom Search API (커뮤니티/웹 검색용)
GOOGLE_API_KEY=your_google_api_key_here # Google Cloud API 키
GOOGLE_CSE_ID=your_google_custom_search_engine_id_here # Google Custom Search Engine ID
# TARGET_COMMUNITY_DOMAINS=dcinside.com,clien.net,... # (settings.py 내 기본값 사용)

# Naver Search API (블로그/뉴스 검색용)
NAVER_CLIENT_ID=your_naver_client_id_here # Naver API 클라이언트 ID
NAVER_CLIENT_SECRET=your_naver_client_secret_here # Naver API 클라이언트 시크릿

# Twitter API v2 (트윗 검색용)
TWITTER_BEARER_TOKEN=your_twitter_bearer_token_here # Twitter API v2 Bearer 토큰

# Reddit API (Reddit 게시물 검색용)
REDDIT_CLIENT_ID=your_reddit_client_id_here # Reddit API 클라이언트 ID
REDDIT_CLIENT_SECRET=your_reddit_client_secret_here # Reddit API 클라이언트 시크릿
REDDIT_USER_AGENT=ComicGeneratorAgent/1.0 (by /u/your_reddit_username) # Reddit API 사용자 에이전트 (규칙 준수)
# REDDIT_USERNAME=your_reddit_script_app_username # (선택 사항)
# REDDIT_PASSWORD=your_reddit_script_app_password # (선택 사항)
# REDDIT_TARGET_SUBREDDITS=news,worldnews,technology,... # (settings.py 내 기본값 사용)

# RSS
# PREDEFINED_RSS_FEEDS=http://...,https://... # (settings.py 내 기본값 사용, 필요시 덮어쓰기)

# --- 도구(Tool) 공통 설정 ---
# TOOL_RETRY_ATTEMPTS=3 # (settings.py 내 기본값 사용)
# TOOL_RETRY_WAIT_MIN=1 # (settings.py 내 기본값 사용)
# TOOL_RETRY_WAIT_MAX=10 # (settings.py 내 기본값 사용)
# TOOL_HTTP_TIMEOUT=15 # (settings.py 내 기본값 사용)
# API_FETCH_TIMEOUT=10 # (settings.py 내 기본값 사용)

# --- 스크래핑(Scraping) 관련 설정 ---
# SCRAPER_USER_AGENT=Mozilla/5.0... # (settings.py 내 기본값 사용)
# SCRAPER_HTTP_TIMEOUT=20 # (settings.py 내 기본값 사용)
# SCRAPER_CONCURRENCY=5 # (settings.py 내 기본값 사용)
# OPINION_SCRAPER_CONCURRENCY=3 # (settings.py 내 기본값 사용)
# MIN_EXTRACTED_TEXT_LENGTH=100 # (settings.py 내 기본값 사용)
# MIN_LANGDETECT_TEXT_LENGTH=50 # (settings.py 내 기본값 사용)

# Selenium WebDriver 설정 (동적 페이지 스크래핑 시 필요할 수 있음)
SELENIUM_GRID_URL= # 예: http://localhost:4444/wd/hub (Selenium Grid 사용 시)
SELENIUM_HEADLESS=True # 브라우저 창 없이 실행 (True/False)
# SELENIUM_RETRY_ATTEMPTS=2 # (settings.py 내 기본값 사용)
# SELENIUM_RETRY_WAIT_SECONDS=1 # (settings.py 내 기본값 사용)

# 스크래핑 지연 시간 (밀리초)
# SCRAPER_MIN_DELAY_MS=1500 # (settings.py 내 기본값 사용)
# SCRAPER_MAX_DELAY_MS=4000 # (settings.py 내 기본값 사용)

# 프록시 설정 (선택 사항)
SCRAPER_USE_PROXY=False # 프록시 사용 여부 (True/False)
SCRAPER_PROXY_URL= # 예: http://user:password@host:port (프록시 사용 시)

# 사용자 에이전트 로테이션 (선택 사항, 구현 시 필요)
SCRAPER_ROTATE_UA=False # User-Agent 로테이션 사용 여부
# USER_AGENT_LIST=ua1,ua2,ua3... # 사용할 User-Agent 목록 (쉼표 구분)

# --- 분석/필터링 도구 설정 ---
# SPAM_KEYWORDS=buy now,click here,... # (settings.py 내 기본값 사용)
# SPAM_MAX_URL_COUNT=2 # (settings.py 내 기본값 사용)
# SPAM_MAX_UPPERCASE_RATIO=0.5 # (settings.py 내 기본값 사용)
# SIMHASH_THRESHOLD=3 # (settings.py 내 기본값 사용)
# SIMHASH_TOKEN_WIDTH=64 # (settings.py 내 기본값 사용)
# KMEANS_DEFAULT_CLUSTERS=5 # (settings.py 내 기본값 사용)
# KMEANS_MIN_SAMPLES=10 # (settings.py 내 기본값 사용)
# TFIDF_MAX_FEATURES=5000 # (settings.py 내 기본값 사용)
# TFIDF_STOP_WORDS=english # (settings.py 내 기본값 사용)
# TFIDF_MIN_DF=2 # (settings.py 내 기본값 사용)
# TFIDF_MAX_DF=0.90 # (settings.py 내 기본값 사용)
# TFIDF_NGRAM_RANGE_MIN=1 # (settings.py 내 기본값 사용)
# TFIDF_NGRAM_RANGE_MAX=2 # (settings.py 내 기본값 사용)
# KMEANS_N_INIT=10 # (settings.py 내 기본값 사용)
# KMEANS_MAX_NO_IMPROVEMENT=20 # (settings.py 내 기본값 사용)

# --- 노드별 특정 설정 ---
# LLM_TEMPERATURE_ANALYSIS=0.2 # (settings.py 내 기본값 사용)
TRANSLATION_ENABLED=False # 번역 기능 활성화 여부 (True/False)
TARGET_TRANSLATION_LANGUAGE=en # 목표 번역 언어 (예: en, ko)
# MAX_ARTICLES_TO_SCRAPE=5 # (settings.py 내 기본값 사용)
# FEQA_THRESHOLD=0.5 # (settings.py 내 기본값 사용)
# SEARCH_RESULT_COUNT=10 # (settings.py 내 기본값 사용)
# TARGET_URLS_PER_KEYWORD=5 # (settings.py 내 기본값 사용)

# Opinion Collector Node 관련 설정
# YOUTUBE_OPINION_MAX_RESULTS=25 # (settings.py 내 기본값 사용)
# TWITTER_OPINION_MAX_RESULTS=15 # (settings.py 내 기본값 사용)
# REDDIT_OPINION_MAX_RESULTS=15 # (settings.py 내 기본값 사용)
# BLOG_OPINION_MAX_RESULTS=10 # (settings.py 내 기본값 사용)
# COMMUNITY_OPINION_MAX_RESULTS=10 # (settings.py 내 기본값 사용)
# MAX_TOTAL_OPINIONS_TARGET=60 # (settings.py 내 기본값 사용)

# 샘플링 시 플랫폼별 최대/최소 의견 수 (JSON 형식 문자열)
# MAX_OPINIONS_PER_PLATFORM_SAMPLING={"Twitter": 15, "Reddit": 15, "YouTube": 10, "Blog": 10, "Community": 10} # (settings.py 내 기본값 사용)
# MIN_OPINIONS_PER_PLATFORM_SAMPLING={"Twitter": 2, "Reddit": 2, "YouTube": 1, "Blog": 2, "Community": 2} # (settings.py 내 기본값 사용)

# 기타 설정
LANGUAGE_FILTER=en,ko # 허용할 언어 목록 (쉼표 구분, 예: en,ko)
TRUSTED_NEWS_DOMAINS= # 신뢰하는 뉴스 도메인 목록 (쉼표 구분, 비워두면 settings.py 기본값 사용)
# EVALUATION_THRESHOLDS={"rouge_l": 0.3, "bert_score": 0.7, "topic_coverage": 0.6} # (settings.py 내 기본값 사용)
# DECISION_LOGIC_THRESHOLDS={"very_low_rouge": 0.1, ...} # (settings.py 내 기본값 사용)

# --- 결과 저장 설정 ---
# RESULTS_DIR= # (settings.py 내 기본값 사용 - results)
SAVE_AGENT_RESULTS=True # 에이전트 최종 결과 저장 여부
SAVE_AGENT_INPUTS=False # 에이전트 입력 데이터 저장 여부
SAVE_DEBUG_INFO=True # 디버깅 정보 저장 여부 (중간 결과 등)
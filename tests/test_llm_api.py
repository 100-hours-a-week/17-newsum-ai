# ai/test_llm_api.py

"""
LLM í API ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import asyncio
import httpx
import time

API_BASE = "http://localhost:8000/api/v1/llm"

async def test_llm_queue_api():
    """LLM í API í…ŒìŠ¤íŠ¸"""
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        print("ğŸ§ª LLM í API í…ŒìŠ¤íŠ¸ ì‹œì‘...\n")
        
        # 1. í ìƒíƒœ í™•ì¸
        print("1ï¸âƒ£ í ìƒíƒœ í™•ì¸...")
        try:
            response = await client.get(f"{API_BASE}/queue/status")
            print(f"   ì‘ë‹µ: {response.status_code}")
            print(f"   ë°ì´í„°: {response.json()}\n")
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}\n")
        
        # 2. LLM ì‘ì—… ìƒì„±
        print("2ï¸âƒ£ LLM ì‘ì—… ìƒì„±...")
        task_payload = {
            "prompt": "Pythonìœ¼ë¡œ Hello Worldë¥¼ ì¶œë ¥í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.",
            "max_tokens": 200,
            "temperature": 0.7
        }
        
        try:
            response = await client.post(f"{API_BASE}/tasks", json=task_payload)
            print(f"   ì‘ë‹µ: {response.status_code}")
            task_data = response.json()
            print(f"   ë°ì´í„°: {task_data}")
            
            if response.status_code == 202:
                task_id = task_data["task_id"]
                print(f"   âœ… ì‘ì—… ìƒì„±ë¨: {task_id}\n")
                
                # 3. ê²°ê³¼ ëŒ€ê¸° ë° ì¡°íšŒ
                print("3ï¸âƒ£ ê²°ê³¼ ëŒ€ê¸° ì¤‘...")
                max_attempts = 30  # ìµœëŒ€ 30ì´ˆ ëŒ€ê¸°
                
                for attempt in range(max_attempts):
                    try:
                        result_response = await client.get(f"{API_BASE}/tasks/{task_id}/result")
                        result_data = result_response.json()
                        
                        if result_data["status"] == "completed":
                            print(f"   âœ… ì™„ë£Œ! (ì‹œë„: {attempt + 1})")
                            print(f"   ê²°ê³¼: {result_data['result']['generated_text'][:200]}...")
                            break
                        elif result_data["status"] == "failed":
                            print(f"   âŒ ì‹¤íŒ¨: {result_data.get('error')}")
                            break
                        else:
                            print(f"   â³ ì²˜ë¦¬ ì¤‘... (ì‹œë„: {attempt + 1})")
                            await asyncio.sleep(1)
                            
                    except Exception as e:
                        print(f"   âŒ ê²°ê³¼ ì¡°íšŒ ì˜¤ë¥˜: {e}")
                        break
                else:
                    print("   âš ï¸ íƒ€ì„ì•„ì›ƒ - ì›Œì»¤ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
            
        except Exception as e:
            print(f"   âŒ ì‘ì—… ìƒì„± ì˜¤ë¥˜: {e}\n")

if __name__ == "__main__":
    print("ğŸ“¡ LLM í API í…ŒìŠ¤íŠ¸")
    print("âš ï¸ ì„œë²„ì™€ ì›Œì»¤ê°€ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n")
    
    try:
        asyncio.run(test_llm_queue_api())
    except KeyboardInterrupt:
        print("\nâš ï¸ í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")

import requests
import io
import time
from PIL import Image

# ì„œë²„ URL
SERVER_URL = "https://publicly-capable-monkfish.ngrok-free.app/"    # static url
TEXT_TO_IMAGE_ENDPOINT = f"{SERVER_URL}/generate/text-to-image"
IMAGE_TO_IMAGE_ENDPOINT = f"{SERVER_URL}/generate/image-to-image"

# ê³µí†µ ì„¤ì •
NEGATIVE_PROMPT = "(worst quality, low quality, normal quality:1.2), deformed, blurry, text, signature"
NUM_IMAGES_TO_GENERATE = 4  # ì´ ìƒì„±í•  ì´ë¯¸ì§€ ìˆ˜
BASE_SEED = 42
LORA_SCALE = 0.0
CONTROLNET_SCALE = 0.7
NUM_INFERENCE_STEPS = 30
GUIDANCE_SCALE = 3.5

# í”„ë ˆì„ë³„ Prompt ëª©ë¡
FRAME_PROMPTS = [
    "A futuristic cityscape with flying cars and neon lights",  # Frame 1
    "A futuristic cityscape at sunset with flying cars and glowing neon lights",  # Frame 2
    "A futuristic cityscape at night with flying cars above illuminated skyscrapers",  # Frame 3
    "A futuristic cityscape during a light rain, flying cars with reflections on the wet streets"  # Frame 4
]

# í˜„ì¬ ìƒì„±í•œ ì´ë¯¸ì§€
current_image = None

# 1. ì²« ë²ˆì§¸ ì´ë¯¸ì§€ëŠ” text-to-image
print("\nğŸš€ [1/4] í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ ì¤‘...")

payload = {
    "prompt": FRAME_PROMPTS[0],
    "negative_prompt": NEGATIVE_PROMPT,
    "num_inference_steps": NUM_INFERENCE_STEPS,
    "guidance_scale": GUIDANCE_SCALE,
    "lora_scale": LORA_SCALE,
    "seed": BASE_SEED
}

try:
    response = requests.post(TEXT_TO_IMAGE_ENDPOINT, json=payload, timeout=300)

    if response.status_code == 200:
        print("âœ… í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„± ì„±ê³µ!")
        current_image = Image.open(io.BytesIO(response.content))
        filename = f"generated_frame_01.png"
        current_image.save(filename)
        print(f"ğŸ’¾ '{filename}'ë¡œ ì €ì¥ ì™„ë£Œ")
    else:
        print(f"âŒ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {response.status_code}")
        print(f"ì˜¤ë¥˜ ë‚´ìš©: {response.text}")
        exit(1)

except requests.exceptions.RequestException as e:
    print(f"âŒ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìš”ì²­ ì‹¤íŒ¨: {e}")
    exit(1)

time.sleep(1)

# 2. ì´í›„ë¶€í„°ëŠ” image-to-image
for idx in range(1, NUM_IMAGES_TO_GENERATE):
    print(f"\nğŸš€ [{idx+1}/{NUM_IMAGES_TO_GENERATE}] ì´ë¯¸ì§€-ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ ì¤‘...")

    img_byte_arr = io.BytesIO()
    current_image.save(img_byte_arr, format='PNG')
    img_byte_arr.seek(0)

    # ìˆ˜ì •ëœ files êµ¬ì„±
    files = {
        "image": ("input.png", img_byte_arr, "image/png"),
        "prompt": (None, FRAME_PROMPTS[idx]),
        "negative_prompt": (None, NEGATIVE_PROMPT),
        "lora_scale": (None, str(LORA_SCALE)),
        "controlnet_scale": (None, str(CONTROLNET_SCALE)),
        "num_inference_steps": (None, str(NUM_INFERENCE_STEPS)),
        "guidance_scale": (None, str(GUIDANCE_SCALE)),
        "seed": (None, str(BASE_SEED + idx))
    }


    try:
        response = requests.post(IMAGE_TO_IMAGE_ENDPOINT, files=files, timeout=300)

        if response.status_code == 200:
            print("âœ… ì´ë¯¸ì§€-ì´ë¯¸ì§€ ìƒì„± ì„±ê³µ!")
            current_image = Image.open(io.BytesIO(response.content))
            filename = f"generated_frame_{idx+1:02d}.png"
            current_image.save(filename)
            print(f"ğŸ’¾ '{filename}'ë¡œ ì €ì¥ ì™„ë£Œ")
        else:
            print(f"âŒ ì´ë¯¸ì§€-ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {response.status_code}")
            print(f"ì˜¤ë¥˜ ë‚´ìš©: {response.text}")
            exit(1)

    except requests.exceptions.RequestException as e:
        print(f"âŒ ì´ë¯¸ì§€-ì´ë¯¸ì§€ ìš”ì²­ ì‹¤íŒ¨: {e}")
        exit(1)

    time.sleep(1)

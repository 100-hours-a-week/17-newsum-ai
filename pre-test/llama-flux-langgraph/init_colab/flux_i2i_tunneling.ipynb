{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# @title 1. ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò\n",
        "%pip install -q fastapi uvicorn[standard]\n",
        "%pip install -q pyngrok>=7.0.0 diffusers>=0.27.0 transformers accelerate\n",
        "%pip install -q peft controlnet_aux torch>=2.0.0 opencv-python-headless Pillow\n",
        "%pip install -q requests safetensors pydantic huggingface_hub python-multipart\n",
        "\n",
        "print(\"‚úÖ ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò ÏôÑÎ£å\")"
      ],
      "metadata": {
        "id": "w-k2065nuVgM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Hugging Face Î°úÍ∑∏Ïù∏ / Ngrok ÏÑ§Ï†ï (Authtoken ÏãúÌÅ¨Î¶ø ÌÇ§)\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "from pyngrok import conf, ngrok\n",
        "\n",
        "# Hugging Face Î∞è ngrok ÌÜ†ÌÅ∞ (Colab SecretÏóêÏÑú Í∞ÄÏ†∏Ïò§Í∏∞)\n",
        "hf_token = userdata.get(\"HF_TOKEN\")        # Hugging Face Token\n",
        "ngrok_token = userdata.get(\"NGROK_TOKEN\")  # ngrok Token\n",
        "\n",
        "if hf_token == None:\n",
        "  print('x')\n",
        "if ngrok_token == None:\n",
        "  print('x')\n",
        "\n",
        "# Ìè¨Ìä∏ ÏÑ§Ï†ï\n",
        "PORT = 8000\n",
        "\n",
        "# hugging face Î°úÍ∑∏Ïù∏\n",
        "print(\"üîë Hugging Face Î°úÍ∑∏Ïù∏ Ï§ë...\")\n",
        "login(token=hf_token)\n",
        "\n",
        "# ngrok ÏÑ§Ï†ï\n",
        "if ngrok_token == \"YOUR_NGROK_AUTHTOKEN\":\n",
        "  print(\"‚ö†Ô∏è Í≤ΩÍ≥†: Ngrok AuthtokenÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî. ÏóÜÏúºÎ©¥ Ngrok ÌÑ∞ÎÑêÏù¥ ÏûëÎèôÌïòÏßÄ ÏïäÏäµÎãàÎã§.\")\n",
        "  print(\"Ngrok ÌÜ†ÌÅ∞ÏùÄ https://dashboard.ngrok.com/get-started/your-authtoken ÏóêÏÑú ÌôïÏù∏ Í∞ÄÎä•Ìï©ÎãàÎã§.\")\n",
        "else:\n",
        "  os.environ['NGROK_AUTHTOKEN'] = ngrok_token\n",
        "  conf.get_default().auth_token = ngrok_token\n",
        "  print(\"‚úÖ Ngrok Authtoken ÏÑ§Ï†ï ÏôÑÎ£å\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0jI1SIruVeF",
        "outputId": "1cd95e60-cc36-4881-ef37-9548c85416a4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîë Hugging Face Î°úÍ∑∏Ïù∏ Ï§ë...\n",
            "‚úÖ Ngrok Authtoken ÏÑ§Ï†ï ÏôÑÎ£å\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. FastAPI Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò ÏΩîÎìú ÏûëÏÑ± (main_server.py ÌååÏùº ÏÉùÏÑ±)\n",
        "# Ïù¥ ÏÖÄÏùÄ FastAPI ÏÑúÎ≤Ñ ÏΩîÎìúÎ•º main_server.py ÌååÏùºÎ°ú Ï†ÄÏû•Ìï©ÎãàÎã§.\n",
        "\n",
        "%%writefile main_server.py\n",
        "import os\n",
        "import io\n",
        "import logging\n",
        "from contextlib import asynccontextmanager\n",
        "from typing import Optional, Any\n",
        "\n",
        "import torch\n",
        "import uvicorn\n",
        "from fastapi import FastAPI, HTTPException, UploadFile, File, Form\n",
        "from fastapi.responses import Response\n",
        "from PIL import Image\n",
        "from diffusers import FluxControlNetModel, FluxControlNetPipeline\n",
        "from controlnet_aux import CannyDetector\n",
        "\n",
        "# --- Configuration ---\n",
        "BASE_MODEL_ID = \"black-forest-labs/FLUX.1-dev\"\n",
        "CONTROLNET_MODEL_ID = \"Shakker-Labs/FLUX.1-dev-ControlNet-Union-Pro-2.0\"\n",
        "DEFAULT_STEPS = 30\n",
        "DEFAULT_GUIDANCE_SCALE = 3.5\n",
        "DEFAULT_CONTROLNET_SCALE = 0.7\n",
        "DEFAULT_LORA_SCALE = 0.8\n",
        "IMAGE_WIDTH = 1024\n",
        "IMAGE_HEIGHT = 1024\n",
        "PORT = 8000\n",
        "\n",
        "# --- Global State ---\n",
        "controlnet_pipe: Optional[FluxControlNetPipeline] = None\n",
        "controlnet_preprocessor: Optional[Any] = None\n",
        "device: Optional[str] = None\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def load_pil_image(image_bytes: bytes) -> Image.Image:\n",
        "    image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
        "    return image\n",
        "\n",
        "def image_to_bytes(image: Image.Image) -> bytes:\n",
        "    byte_arr = io.BytesIO()\n",
        "    image.save(byte_arr, format='PNG')\n",
        "    byte_arr.seek(0)\n",
        "    return byte_arr.getvalue()\n",
        "\n",
        "def get_generator(seed: Optional[int] = None) -> torch.Generator:\n",
        "    if seed is None:\n",
        "        seed = torch.randint(0, 2**32 - 1, (1,)).item()\n",
        "    logger.info(f\"Using seed: {seed}\")\n",
        "    return torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "def prepare_control_image(uploaded_image: UploadFile) -> Image.Image:\n",
        "    if controlnet_preprocessor is None:\n",
        "        raise RuntimeError(\"ControlNet preprocessor not loaded.\")\n",
        "    image = load_pil_image(uploaded_image.file.read())\n",
        "    control_image = controlnet_preprocessor(image)\n",
        "    return control_image\n",
        "\n",
        "# --- Model Loading ---\n",
        "def load_models():\n",
        "    global controlnet_pipe, controlnet_preprocessor, device\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    logger.info(f\"Using device: {device}\")\n",
        "    dtype = torch.bfloat16 if device == \"cuda\" and torch.cuda.is_bf16_supported() else torch.float16\n",
        "\n",
        "    try:\n",
        "        logger.info(\"Loading ControlNet model...\")\n",
        "        controlnet_model = FluxControlNetModel.from_pretrained(CONTROLNET_MODEL_ID, torch_dtype=dtype)\n",
        "        controlnet_pipe = FluxControlNetPipeline.from_pretrained(BASE_MODEL_ID, controlnet=controlnet_model, torch_dtype=dtype)\n",
        "        controlnet_pipe.to(device)\n",
        "        controlnet_pipe.enable_model_cpu_offload()\n",
        "        controlnet_pipe.enable_attention_slicing()\n",
        "\n",
        "        logger.info(\"Loading Canny preprocessor...\")\n",
        "        controlnet_preprocessor = CannyDetector()\n",
        "        if hasattr(controlnet_preprocessor, 'to'):\n",
        "            controlnet_preprocessor.to(device)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(\"Fatal error during model loading\")\n",
        "        raise RuntimeError(f\"Failed to load models: {e}\")\n",
        "\n",
        "    logger.info(\"‚úÖ Model loading complete.\")\n",
        "\n",
        "# --- FastAPI Setup ---\n",
        "@asynccontextmanager\n",
        "async def lifespan(app: FastAPI):\n",
        "    logger.info(\"Application startup...\")\n",
        "    load_models()\n",
        "    yield\n",
        "    logger.info(\"Application shutdown...\")\n",
        "    global controlnet_pipe\n",
        "    del controlnet_pipe\n",
        "    if device == 'cuda':\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "app = FastAPI(lifespan=lifespan, title=\"Flux ControlNet Image-to-Image API\")\n",
        "\n",
        "# --- API Endpoint ---\n",
        "@app.post(\"/generate/image-to-image\", summary=\"Generate Image using ControlNet\", response_class=Response)\n",
        "async def generate_image_to_image(\n",
        "    prompt: str = Form(...),\n",
        "    negative_prompt: Optional[str] = Form(\"\"),\n",
        "    lora_scale: Optional[float] = Form(DEFAULT_LORA_SCALE),\n",
        "    controlnet_scale: float = Form(DEFAULT_CONTROLNET_SCALE),\n",
        "    num_inference_steps: int = Form(DEFAULT_STEPS),\n",
        "    guidance_scale: float = Form(DEFAULT_GUIDANCE_SCALE),\n",
        "    seed: Optional[int] = Form(None),\n",
        "    image: UploadFile = File(...)\n",
        "):\n",
        "    if controlnet_pipe is None:\n",
        "        raise HTTPException(status_code=503, detail=\"ControlNet pipeline not ready.\")\n",
        "\n",
        "    control_image = prepare_control_image(image)\n",
        "\n",
        "    generator = get_generator(seed)\n",
        "\n",
        "    try:\n",
        "        with torch.inference_mode():\n",
        "            result = controlnet_pipe(\n",
        "                prompt=prompt,\n",
        "                control_image=control_image,  # ‚ú® Ï£ºÏùò: FluxControlNetPipelineÏùÄ control_imageÎ•º Î∞õÏùÑ Í≤É\n",
        "                width=IMAGE_WIDTH,\n",
        "                height=IMAGE_HEIGHT,\n",
        "                num_inference_steps=num_inference_steps,\n",
        "                guidance_scale=guidance_scale,\n",
        "                controlnet_conditioning_scale=controlnet_scale,\n",
        "                generator=generator,\n",
        "            )\n",
        "\n",
        "        if hasattr(result, 'images'):\n",
        "            output_image = result.images[0]\n",
        "        elif isinstance(result, list) and isinstance(result[0], Image.Image):\n",
        "            output_image = result[0]\n",
        "        else:\n",
        "            raise ValueError(\"Could not extract image from pipeline result.\")\n",
        "\n",
        "        img_bytes = image_to_bytes(output_image)\n",
        "        return Response(content=img_bytes, media_type=\"image/png\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(\"Image-to-Image generation failed\")\n",
        "        raise HTTPException(status_code=500, detail=f\"Generation failed: {e}\")\n",
        "\n",
        "# --- Main ---\n",
        "if __name__ == \"__main__\":\n",
        "    logger.info(\"Starting Uvicorn server...\")\n",
        "    uvicorn.run(\"main_server:app\", host=\"0.0.0.0\", port=PORT, reload=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kbHyC1SuVaD",
        "outputId": "f905ed05-11b4-4ae7-b47f-27f99ed7696f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main_server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. ngrok ÌÑ∞ÎÑêÎßÅ Î∞è api Ï†úÍ≥µ\n",
        "# ÌôòÍ≤Ω Î≥ÄÏàò ÏÑ§Ï†ï\n",
        "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
        "\n",
        "import time\n",
        "import os\n",
        "import subprocess\n",
        "from pyngrok import ngrok\n",
        "import logging\n",
        "\n",
        "# Î°úÍπÖ ÏÑ§Ï†ï\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "pyngrok_logger = logging.getLogger(\"pyngrok\")\n",
        "pyngrok_logger.setLevel(logging.INFO)\n",
        "\n",
        "# --- ÏÑ§Ï†ï ---\n",
        "LOG_FILE = \"uvicorn_server.log\"\n",
        "PORT = 8000  # main_server.py ÎÇ¥Î∂Ä Ìè¨Ìä∏ÏôÄ ÏùºÏπò\n",
        "STATIC_NGROK_DOMAIN = \"publicly-capable-monkfish.ngrok-free.app\"  # Í≥†Ï†ï ÎèÑÎ©îÏù∏\n",
        "\n",
        "# --- Í∏∞Ï°¥ ÏÑúÎ≤Ñ Î∞è ngrok ÌîÑÎ°úÏÑ∏Ïä§ Ï¢ÖÎ£å ---\n",
        "print(\"‚ÑπÔ∏è Í∏∞Ï°¥ Uvicorn/Ngrok ÌîÑÎ°úÏÑ∏Ïä§ Ï¢ÖÎ£å ÏãúÎèÑ...\")\n",
        "\n",
        "try:\n",
        "    ngrok.kill()\n",
        "    print(\"   - ngrok ÌîÑÎ°úÏÑ∏Ïä§ Ï¢ÖÎ£å ÏôÑÎ£å (pyngrok).\")\n",
        "    time.sleep(2)\n",
        "except Exception as e:\n",
        "    pyngrok_logger.warning(f\"ngrok.kill() Ïã§Ìñâ Ï§ë Ïò§Î•ò Î∞úÏÉù (Î¨¥Ïãú Í∞ÄÎä•): {e}\")\n",
        "\n",
        "subprocess.run(['pkill', '-f', 'uvicorn main_server:app'], stderr=subprocess.DEVNULL)\n",
        "subprocess.run(['pkill', '-f', f'ngrok.*http.*{PORT}'], stderr=subprocess.DEVNULL)\n",
        "subprocess.run(['pkill', '-f', '/root/.config/ngrok/ngrok'], stderr=subprocess.DEVNULL)\n",
        "time.sleep(3)\n",
        "\n",
        "# --- FastAPI ÏÑúÎ≤Ñ Î∞±Í∑∏ÎùºÏö¥Îìú Ïã§Ìñâ ---\n",
        "print(f\"üöÄ FastAPI ÏÑúÎ≤ÑÎ•º Î∞±Í∑∏ÎùºÏö¥ÎìúÏóêÏÑú ÏãúÏûëÌï©ÎãàÎã§... Î°úÍ∑∏ ÌååÏùº: {LOG_FILE}\")\n",
        "nohup_cmd = f\"nohup python main_server.py > {LOG_FILE} 2>&1 &\"\n",
        "subprocess.Popen(nohup_cmd, shell=True)\n",
        "time.sleep(5)  # ÏÑúÎ≤Ñ Ï¥àÍ∏∞ Î∂ÄÌåÖ ÎåÄÍ∏∞\n",
        "\n",
        "# --- ngrok static ÎèÑÎ©îÏù∏ÏúºÎ°ú Ïó∞Í≤∞ ---\n",
        "print(f\"üåê ngrok static domain Ïó∞Í≤∞ ÏãúÎèÑ ({STATIC_NGROK_DOMAIN})...\")\n",
        "public_url = ngrok.connect(\n",
        "    addr=PORT,\n",
        "    proto=\"http\",\n",
        "    domain=STATIC_NGROK_DOMAIN\n",
        ")\n",
        "print(f\"‚úÖ Í≥†Ï†ï URL Ïó∞Í≤∞ ÏôÑÎ£å: {public_url}\")\n",
        "\n",
        "# --- ÏÑúÎ≤Ñ Ï§ÄÎπÑ ÎåÄÍ∏∞ (Î™®Îç∏ Î°úÎî© ÏãúÍ∞Ñ ÌôïÎ≥¥) ---\n",
        "wait_seconds = 200  # ÌïÑÏöîÏóê Îî∞Îùº Ï°∞Ï†ï\n",
        "print(f\"‚è≥ ÏÑúÎ≤Ñ Î∞è Î™®Îç∏ Ï§ÄÎπÑ ÎåÄÍ∏∞ Ï§ë ({wait_seconds}Ï¥à)...\")\n",
        "for i in range(wait_seconds):\n",
        "    print(str(i), end=\" \", flush=True)\n",
        "    if (i + 1) % 30 == 0:\n",
        "        print()\n",
        "    time.sleep(1)\n",
        "print(\"\\n‚úÖ ÏÑúÎ≤Ñ Ï§ÄÎπÑ ÎåÄÍ∏∞ ÏôÑÎ£å.\")\n",
        "\n",
        "# --- Í≤∞Í≥º Ï∂úÎ†• ---\n",
        "print(f\"\\nüéØ ÏÑúÎ≤ÑÍ∞Ä Î∞±Í∑∏ÎùºÏö¥ÎìúÏóêÏÑú Ïã§ÌñâÎêòÍ≥† ÏûàÏúºÎ©∞ Ïô∏Î∂Ä Ï†ëÏÜç URLÏùÄ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§:\")\n",
        "print(f\"üîó {public_url}\")\n",
        "\n",
        "print(\"\\n--- Ïã§Ìñâ Ï§ëÏù∏ Í¥ÄÎ†® ÌîÑÎ°úÏÑ∏Ïä§ (Ï∞∏Í≥†Ïö©) ---\")\n",
        "!ps -ef | grep -E \"main_server.py|ngrok\" | grep -v -E \"grep|pkill|colab\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCqXd-e1uVX7",
        "outputId": "753c0c72-cb92-4a36-ba74-6d80ac64baa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
            "‚ÑπÔ∏è Í∏∞Ï°¥ Uvicorn/Ngrok ÌîÑÎ°úÏÑ∏Ïä§ Ï¢ÖÎ£å ÏãúÎèÑ...\n",
            "   - ngrok ÌîÑÎ°úÏÑ∏Ïä§ Ï¢ÖÎ£å ÏôÑÎ£å (pyngrok).\n",
            "üöÄ FastAPI ÏÑúÎ≤ÑÎ•º Î∞±Í∑∏ÎùºÏö¥ÎìúÏóêÏÑú ÏãúÏûëÌï©ÎãàÎã§... Î°úÍ∑∏ ÌååÏùº: uvicorn_server.log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyngrok.ngrok:Opening tunnel named: http-8000-dce04423-330f-4cb6-8795-06f1757b8d37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåê ngrok static domain Ïó∞Í≤∞ ÏãúÎèÑ (publicly-capable-monkfish.ngrok-free.app)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pyngrok.process:Overriding default auth token\n",
            "INFO:pyngrok.process.ngrok:t=2025-04-23T10:45:14+0000 lvl=info msg=\"no configuration paths supplied\"\n",
            "INFO:pyngrok.process.ngrok:t=2025-04-23T10:45:14+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.config/ngrok/ngrok.yml\n",
            "INFO:pyngrok.process.ngrok:t=2025-04-23T10:45:14+0000 lvl=info msg=\"open config file\" path=/root/.config/ngrok/ngrok.yml err=nil\n",
            "INFO:pyngrok.process.ngrok:t=2025-04-23T10:45:14+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "INFO:pyngrok.process.ngrok:t=2025-04-23T10:45:14+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "INFO:pyngrok.process.ngrok:t=2025-04-23T10:45:14+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "INFO:pyngrok.process.ngrok:t=2025-04-23T10:45:14+0000 lvl=info msg=start pg=/api/tunnels id=7d2243fd67d7674d\n",
            "INFO:pyngrok.process.ngrok:t=2025-04-23T10:45:14+0000 lvl=info msg=end pg=/api/tunnels id=7d2243fd67d7674d status=200 dur=414.807¬µs\n",
            "INFO:pyngrok.process.ngrok:t=2025-04-23T10:45:14+0000 lvl=info msg=start pg=/api/tunnels id=cba4ee7582d8fab2\n",
            "INFO:pyngrok.process.ngrok:t=2025-04-23T10:45:14+0000 lvl=info msg=end pg=/api/tunnels id=cba4ee7582d8fab2 status=200 dur=109.434¬µs\n",
            "INFO:pyngrok.process.ngrok:t=2025-04-23T10:45:14+0000 lvl=info msg=start pg=/api/tunnels id=8963d9893abb570b\n",
            "INFO:pyngrok.process.ngrok:t=2025-04-23T10:45:14+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=http-8000-dce04423-330f-4cb6-8795-06f1757b8d37 addr=http://localhost:8000 url=https://publicly-capable-monkfish.ngrok-free.app\n",
            "INFO:pyngrok.process.ngrok:t=2025-04-23T10:45:14+0000 lvl=info msg=end pg=/api/tunnels id=8963d9893abb570b status=201 dur=32.321713ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Í≥†Ï†ï URL Ïó∞Í≤∞ ÏôÑÎ£å: NgrokTunnel: \"https://publicly-capable-monkfish.ngrok-free.app\" -> \"http://localhost:8000\"\n",
            "‚è≥ ÏÑúÎ≤Ñ Î∞è Î™®Îç∏ Ï§ÄÎπÑ ÎåÄÍ∏∞ Ï§ë (200Ï¥à)...\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \n",
            "30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 \n",
            "60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 \n",
            "90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 \n",
            "120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 \n",
            "150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 \n",
            "180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 \n",
            "‚úÖ ÏÑúÎ≤Ñ Ï§ÄÎπÑ ÎåÄÍ∏∞ ÏôÑÎ£å.\n",
            "\n",
            "üéØ ÏÑúÎ≤ÑÍ∞Ä Î∞±Í∑∏ÎùºÏö¥ÎìúÏóêÏÑú Ïã§ÌñâÎêòÍ≥† ÏûàÏúºÎ©∞ Ïô∏Î∂Ä Ï†ëÏÜç URLÏùÄ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§:\n",
            "üîó NgrokTunnel: \"https://publicly-capable-monkfish.ngrok-free.app\" -> \"http://localhost:8000\"\n",
            "\n",
            "--- Ïã§Ìñâ Ï§ëÏù∏ Í¥ÄÎ†® ÌîÑÎ°úÏÑ∏Ïä§ (Ï∞∏Í≥†Ïö©) ---\n",
            "root        5042       1 75 10:45 ?        00:02:35 python3 main_server.py\n",
            "root        5083    4474  0 10:45 ?        00:00:00 /root/.config/ngrok/ngrok start --none --log=stdout --authtoken=2w407BMGqxf9I8D2pqcULgTqTQ3_5kTpwTjAKu8ummsSXG1kn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # @title 5. API ÏÑúÎ≤Ñ ÏöîÏ≤≠, CSV Í∏∞Î∞ò Îã§Ïàò ÌîÑÎ°¨ÌîÑÌä∏ ÏÇ¨Ïö© Î∞è Google Drive Ï†ÄÏû•\n",
        "# import requests\n",
        "# import base64\n",
        "# import io\n",
        "# from PIL import Image\n",
        "# from IPython.display import display, HTML\n",
        "# import time\n",
        "# import json\n",
        "# import os # os Î™®Îìà Ï∂îÍ∞Ä\n",
        "# import pandas as pd # pandas ÎùºÏù¥Î∏åÎü¨Î¶¨ Ï∂îÍ∞Ä\n",
        "# from google.colab import drive # Google Drive Ïó∞ÎèôÏö©\n",
        "\n",
        "# # --- Google Drive ÎßàÏö¥Ìä∏ ---\n",
        "# try:\n",
        "#     drive.mount('/content/drive')\n",
        "#     drive_mounted = True\n",
        "#     print(\"‚úÖ Google Drive ÎßàÏö¥Ìä∏ ÏÑ±Í≥µ!\")\n",
        "# except Exception as e:\n",
        "#     print(f\"‚ö†Ô∏è Google Drive ÎßàÏö¥Ìä∏ Ïã§Ìå®: {e}\")\n",
        "#     print(\"   Ïù¥ÎØ∏ÏßÄÎäî Google DriveÏóê Ï†ÄÏû•ÎêòÏßÄ ÏïäÏäµÎãàÎã§.\")\n",
        "#     drive_mounted = False\n",
        "\n",
        "# # --- ÏÑ§Ï†ï ---\n",
        "# # 5Î≤à ÏÖÄ Ï∂úÎ†•ÏóêÏÑú ÌôïÏù∏Ìïú Ngrok URL (Ïù¥Ï†Ñ ÏÑ±Í≥µ Ïãú ÏÇ¨Ïö©Ìïú URL Ïú†ÏßÄ)\n",
        "# NGROK_URL = \"https://7178-34-139-109-175.ngrok-free.app\" # Ïù¥Ï†Ñ ÏÑ±Í≥µ Ïãú ÏÇ¨Ïö©Ìïú URL\n",
        "\n",
        "# # --- Google Drive Ï†ÄÏû• Í≤ΩÎ°ú ÏÑ§Ï†ï ---\n",
        "# SAVE_DIR = \"/content/drive/MyDrive/FluxComicOutput\" # ÏõêÌïòÎäî Í≤ΩÎ°úÎ°ú ÏàòÏ†ïÌïòÏÑ∏Ïöî.\n",
        "# if drive_mounted:\n",
        "#     try:\n",
        "#         os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "#         print(f\"‚úÖ Ïù¥ÎØ∏ÏßÄÎ•º Ï†ÄÏû•Ìï† Í≤ΩÎ°ú: {SAVE_DIR}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"‚ö†Ô∏è Google Drive Ï†ÄÏû• Í≤ΩÎ°ú ÏÉùÏÑ± Ïã§Ìå® ({SAVE_DIR}): {e}\")\n",
        "#         print(\"   Ïù¥ÎØ∏ÏßÄÎäî Google DriveÏóê Ï†ÄÏû•ÎêòÏßÄ ÏïäÏäµÎãàÎã§.\")\n",
        "#         drive_mounted = False\n",
        "\n",
        "# # --- CSVÏóêÏÑú ÌîÑÎ°¨ÌîÑÌä∏ Î°úÎìú ---\n",
        "# CSV_FILE_PATH = 'news_based_comic_prompts_sample.csv' # ÏóÖÎ°úÎìúÌïú CSV ÌååÏùº Ïù¥Î¶Ñ\n",
        "\n",
        "# # --- ÏÉùÏÑ±Ìï† Case ID Î¶¨Ïä§Ìä∏ ---\n",
        "# # ÏïÑÎûò Î¶¨Ïä§Ìä∏Ïóê ÏÉùÏÑ±ÌïòÍ≥† Ïã∂ÏùÄ ÎßåÌôîÏùò case_id Î≤àÌò∏Îì§ÏùÑ ÎÑ£ÏúºÏÑ∏Ïöî.\n",
        "# # Ïòà: [1, 5, 10] ÎòêÎäî list(range(1, 6)) -> 1Î≤àÎ∂ÄÌÑ∞ 5Î≤àÍπåÏßÄ ÏÉùÏÑ±\n",
        "# case_ids_to_generate = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20] # <--- ÏÉùÏÑ±Ìï† case_id Î¶¨Ïä§Ìä∏Î•º Ïó¨Í∏∞Ïóê ÏßÄÏ†ïÌïòÏÑ∏Ïöî.\n",
        "\n",
        "# try:\n",
        "#     df_all_panels = pd.read_csv(CSV_FILE_PATH) # Ï†ÑÏ≤¥ CSV ÌååÏùºÏùÑ ÌïúÎ≤àÎßå ÏùΩÏùå\n",
        "#     print(f\"‚úÖ '{CSV_FILE_PATH}' ÌååÏùº Î°úÎìú ÏÑ±Í≥µ!\")\n",
        "#     csv_loaded = True\n",
        "# except FileNotFoundError:\n",
        "#     print(f\"‚ùå Ïò§Î•ò: '{CSV_FILE_PATH}' ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. ÌååÏùºÏùÑ Colab ÌôòÍ≤ΩÏóê ÏóÖÎ°úÎìúÌñàÎäîÏßÄ ÌôïÏù∏ÌïòÏÑ∏Ïöî.\")\n",
        "#     csv_loaded = False\n",
        "# except Exception as e:\n",
        "#     print(f\"‚ùå CSV ÌååÏùº Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}\")\n",
        "#     csv_loaded = False\n",
        "# # --------------------------\n",
        "\n",
        "# if NGROK_URL == \"YOUR_NGROK_PUBLIC_URL\":\n",
        "#     print(\"‚ö†Ô∏è Í≤ΩÍ≥†: NGROK_URL Î≥ÄÏàòÏóê 5Î≤à ÏÖÄÏóêÏÑú ÏñªÏùÄ Ïã§Ï†ú Ngrok Ï£ºÏÜåÎ•º ÏûÖÎ†•Ìï¥Ïïº Ìï©ÎãàÎã§!\")\n",
        "# elif not csv_loaded: # CSV Î°úÎìú Ïã§Ìå® Ïãú Ïã§Ìñâ Ï§ëÏßÄ\n",
        "#      print(\"‚ùå CSV ÌååÏùº Î°úÎìú Ïã§Ìå®Î°ú Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ±ÏùÑ ÏßÑÌñâÌï† Ïàò ÏóÜÏäµÎãàÎã§.\")\n",
        "# else:\n",
        "#     # API ÏóîÎìúÌè¨Ïù∏Ìä∏ Ï£ºÏÜå ÏÑ§Ï†ï\n",
        "#     TEXT_TO_IMAGE_URL = f\"{NGROK_URL}/generate/text-to-image\"\n",
        "#     # IMAGE_TO_IMAGE_URL = f\"{NGROK_URL}/generate/image-to-image\" # ÌòÑÏû¨ ÎπÑÌôúÏÑ±Ìôî ÏÉÅÌÉú\n",
        "#     CHANGE_LORA_URL = f\"{NGROK_URL}/change-lora\"\n",
        "#     STATUS_URL = f\"{NGROK_URL}/\"\n",
        "\n",
        "#     # --- Í∏∞Î≥∏ ÏÉùÏÑ± ÌååÎùºÎØ∏ÌÑ∞ ---\n",
        "#     negative_prompt = \"(worst quality, low quality, normal quality:1.2), deformed, blurry, text, signature\"\n",
        "#     num_inference_steps = 30\n",
        "#     guidance_scale = 3.5\n",
        "#     lora_scale_vintage = 0.0 # LoRA ÏÇ¨Ïö© Ïãú Í∞í Ï°∞Ï†ï\n",
        "\n",
        "#     # --- ÏÑúÎ≤Ñ ÏÉÅÌÉú ÌôïÏù∏ (Ï†ÑÏ≤¥ Ïã§Ìñâ Ï†Ñ Ìïú Î≤àÎßå) ---\n",
        "#     print(f\"\\nAPI ÏÑúÎ≤Ñ ({NGROK_URL}) ÏÉÅÌÉú ÌôïÏù∏ Ï§ë...\")\n",
        "#     server_ok = False\n",
        "#     try:\n",
        "#         status_response = requests.get(STATUS_URL, timeout=30)\n",
        "#         status_response.raise_for_status()\n",
        "#         print(\"\\n--- ÏÑúÎ≤Ñ ÏÉÅÌÉú ---\")\n",
        "#         print(json.dumps(status_response.json(), indent=2))\n",
        "#         print(\"------------------\\n\")\n",
        "#         server_ok = True\n",
        "#     except requests.exceptions.RequestException as e:\n",
        "#         print(f\"‚ùå ÏÑúÎ≤Ñ ÏÉÅÌÉú ÌôïÏù∏ Ïã§Ìå®: {e}. Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ±ÏùÑ ÏßÑÌñâÌï† Ïàò ÏóÜÏäµÎãàÎã§.\")\n",
        "#     # ------------------------------------\n",
        "\n",
        "#     # --- ÏÉùÏÑ± Ïã§Ìñâ (ÏßÄÏ†ïÎêú Î™®Îì† Case IDÏóê ÎåÄÌï¥ Î∞òÎ≥µ) ---\n",
        "#     if server_ok and csv_loaded:\n",
        "#         print(f\"üöÄ Ï¥ù {len(case_ids_to_generate)}Í∞úÏùò ÎßåÌôî ÏÉùÏÑ±ÏùÑ ÏãúÏûëÌï©ÎãàÎã§: {case_ids_to_generate}\")\n",
        "\n",
        "#         # ÏßÄÏ†ïÎêú Î™®Îì† case_idÏóê ÎåÄÌï¥ Ïô∏Î∂Ä Î£®ÌîÑ Ïã§Ìñâ\n",
        "#         for selected_case_id in case_ids_to_generate:\n",
        "#             print(f\"\\n===================================\")\n",
        "#             print(f\"‚è≥ Case ID {selected_case_id} Ï≤òÎ¶¨ ÏãúÏûë...\")\n",
        "#             print(f\"===================================\")\n",
        "\n",
        "#             generated_images = [] # Í∞Å ÏºÄÏù¥Ïä§Î≥Ñ Ïù¥ÎØ∏ÏßÄ Î¶¨Ïä§Ìä∏ Ï¥àÍ∏∞Ìôî (Î©îÎ™®Î¶¨ Í¥ÄÎ¶¨)\n",
        "\n",
        "#             # --- Ìï¥Îãπ Case IDÏùò Ìå®ÎÑê Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ ---\n",
        "#             selected_panels_df = df_all_panels[df_all_panels['case_id'] == selected_case_id].sort_values(by='panel')\n",
        "\n",
        "#             if selected_panels_df.empty:\n",
        "#                 print(f\"‚ùå Ïò§Î•ò: CSV ÌååÏùºÏóêÏÑú case_id {selected_case_id}Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. Îã§Ïùå case_idÎ°ú ÎÑòÏñ¥Í∞ëÎãàÎã§.\")\n",
        "#                 continue # ÌòÑÏû¨ case_id Í±¥ÎÑàÎõ∞Í≥† Îã§Ïùå Î£®ÌîÑ Î∞òÎ≥µ Ïã§Ìñâ\n",
        "\n",
        "#             comic_panels = selected_panels_df[['prompt', 'seed']].to_dict('records')\n",
        "#             print(f\"‚úÖ Case ID {selected_case_id}Ïóê ÎåÄÌïú Ìå®ÎÑê Îç∞Ïù¥ÌÑ∞ Î°úÎìú ÏôÑÎ£å ({len(comic_panels)}Í∞ú Ìå®ÎÑê).\")\n",
        "#             # ------------------------------------\n",
        "\n",
        "#             # --- Í∞Å Ìå®ÎÑê Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ± (ÎÇ¥Î∂Ä Î£®ÌîÑ) ---\n",
        "#             for i, panel_data in enumerate(comic_panels):\n",
        "#                 if 'prompt' not in panel_data or 'seed' not in panel_data:\n",
        "#                      print(f\"‚ö†Ô∏è Ïª∑ {i+1} Îç∞Ïù¥ÌÑ∞ ÌòïÏãù Ïò§Î•ò. Í±¥ÎÑà<0xEB><0x9C><0x84>ÎãàÎã§: {panel_data}\")\n",
        "#                      continue\n",
        "\n",
        "#                 panel_prompt = panel_data['prompt']\n",
        "#                 panel_seed = int(panel_data['seed'])\n",
        "\n",
        "#                 print(f\"  Ïª∑ {i+1}/{len(comic_panels)} ÏÉùÏÑ± Ï§ë: \\\"{panel_prompt[:50]}...\\\" (Seed: {panel_seed})\")\n",
        "\n",
        "#                 payload = {\n",
        "#                     \"prompt\": panel_prompt,\n",
        "#                     \"negative_prompt\": negative_prompt,\n",
        "#                     \"num_inference_steps\": num_inference_steps,\n",
        "#                     \"guidance_scale\": guidance_scale,\n",
        "#                     \"lora_scale\": lora_scale_vintage,\n",
        "#                     \"seed\": panel_seed\n",
        "#                 }\n",
        "\n",
        "#                 try:\n",
        "#                     start_req_time = time.time()\n",
        "#                     response = requests.post(TEXT_TO_IMAGE_URL, json=payload, timeout=300) # ÌÉÄÏûÑÏïÑÏõÉ ÎäòÎ¶º\n",
        "#                     end_req_time = time.time()\n",
        "\n",
        "#                     if response.status_code == 200:\n",
        "#                         print(f\"    ‚úÖ Ïª∑ {i+1} ÏÉùÏÑ± ÏÑ±Í≥µ! (ÏÜåÏöî ÏãúÍ∞Ñ: {end_req_time - start_req_time:.2f}Ï¥à)\")\n",
        "#                         try:\n",
        "#                             img = Image.open(io.BytesIO(response.content))\n",
        "#                             generated_images.append(img)\n",
        "#                             display(img)\n",
        "\n",
        "#                             # --- Google Drive Ï†ÄÏû• Î°úÏßÅ ---\n",
        "#                             if drive_mounted:\n",
        "#                                 try:\n",
        "#                                     filename = f\"comic_case_{selected_case_id}_panel_{i+1}_seed_{panel_seed}.png\"\n",
        "#                                     save_path = os.path.join(SAVE_DIR, filename)\n",
        "#                                     img.save(save_path)\n",
        "#                                     print(f\"      üíæ Ïù¥ÎØ∏ÏßÄÎ•º Google DriveÏóê Ï†ÄÏû•ÌñàÏäµÎãàÎã§: {save_path}\")\n",
        "#                                 except Exception as e:\n",
        "#                                     print(f\"      ‚ö†Ô∏è Google Drive Ï†ÄÏû• Ïã§Ìå® ({filename}): {e}\")\n",
        "#                             # ----------------------------\n",
        "\n",
        "#                         except Exception as e:\n",
        "#                             print(f\"    ‚ö†Ô∏è Ïù¥ÎØ∏ÏßÄÎ•º ÌëúÏãú/Ï≤òÎ¶¨ÌïòÎäî Ï§ë Ïò§Î•ò: {e}\")\n",
        "#                     else:\n",
        "#                         print(f\"    ‚ùå Ïª∑ {i+1} ÏÉùÏÑ± Ïã§Ìå®: Status Code {response.status_code}\")\n",
        "#                         try:\n",
        "#                             print(f\"       Ïò§Î•ò Î©îÏãúÏßÄ: {response.json()}\")\n",
        "#                         except json.JSONDecodeError:\n",
        "#                             print(f\"       Ïò§Î•ò ÎÇ¥Ïö©: {response.text}\")\n",
        "#                 except requests.exceptions.Timeout:\n",
        "#                      print(f\"  ‚ùå Ïª∑ {i+1} ÏöîÏ≤≠ ÏãúÍ∞Ñ Ï¥àÍ≥º (Timeout). Îã§Ïùå Ìå®ÎÑêÎ°ú ÎÑòÏñ¥Í∞ëÎãàÎã§.\")\n",
        "#                 except requests.exceptions.RequestException as e:\n",
        "#                      print(f\"  ‚ùå Ïª∑ {i+1} ÏöîÏ≤≠ Ïã§Ìå®: {e}\")\n",
        "#                 except Exception as e:\n",
        "#                      print(f\"  ‚ùå Ïª∑ {i+1} Ï≤òÎ¶¨ Ï§ë ÏòàÏÉÅÏπò Î™ªÌïú Ïò§Î•ò: {e}\")\n",
        "\n",
        "#                 time.sleep(1) # Ìå®ÎÑê Í∞Ñ ÎîúÎ†àÏù¥\n",
        "\n",
        "#             print(f\"\\nüéâ Case ID {selected_case_id} ÎßåÌôî Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ± ÏôÑÎ£å!\")\n",
        "#             # time.sleep(5) # ÌïÑÏöîÌïòÎã§Î©¥ ÏºÄÏù¥Ïä§ ÏÇ¨Ïù¥Ïóê Ï∂îÍ∞Ä ÎîúÎ†àÏù¥\n",
        "\n",
        "#         print(f\"\\n===================================\")\n",
        "#         print(f\"‚úÖ Î™®Îì† ÏöîÏ≤≠Îêú ÎßåÌôî ÏÉùÏÑ± ÏûëÏóÖ ÏôÑÎ£å!\")\n",
        "#         print(f\"===================================\")\n",
        "#         # --- ÏÉùÏÑ± Ïã§Ìñâ (Outer Loop for Case IDs) --- ÎÅù ---\n",
        "\n",
        "#     # --- (ÏÑ†ÌÉù ÏÇ¨Ìï≠) Îã§Î•∏ LoRA Î°ú Ïä§ÌÉÄÏùº Î≥ÄÍ≤Ω ÌõÑ Ïû¨ÏÉùÏÑ± ---\n",
        "#     # (Ïù¥ Î∂ÄÎ∂ÑÏùÄ Í∑∏ÎåÄÎ°ú Ïú†ÏßÄ)"
      ],
      "metadata": {
        "id": "WbBRc0ye4_NW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
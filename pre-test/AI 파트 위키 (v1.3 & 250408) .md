# AI 파트 위키 (v1.3 / 250408) 

## 목차
- [1. 개요](#1-개요)
- [2. 리소스 현황](#2-리소스-현황)
- [3. 모델 및 프레임워크 연구/테스트](#3-모델-및-프레임워크-연구테스트)
- [4. 개발 계획 및 일정](#4-개발-계획-및-일정)
- [5. API 정의 (TBD)](#5-api-정의-tbd)
- [6. 배포 환경 및 CI/CD 파이프라인 (TBD)](#6-배포-환경-및-cicd-파이프라인-tbd)
- [7. 코드 품질 및 컨벤션 (TBD)](#7-코드-품질-및-컨벤션-tbd)
- [8. 트러블슈팅](#8-트러블슈팅)

## 1. 개요

본 문서는 프로젝트 내 AI 기능(이미지 생성, LLM 활용 등) 개발을 위한 연구, 테스트, 개발 계획, 운영 방안 등을 기록하고 공유하는 것을 목적으로 합니다. 주요 목표는 뉴스 콘텐츠에 적합한 이미지를 생성하고, 필요한 텍스트 처리(예: 요약, 시나리오 변환) 기능을 제공하는 것입니다.

## 2. 리소스 현황

AI 모델 연구, 개발, 서빙을 위해 현재 확보 및 고려 중인 리소스는 다음과 같습니다.

* **구독 서비스:**
    * Google Colab Pro+ 구독권 (2명)
* **로컬 개발 환경:**
    * RTX 4080 Super 탑재 로컬 PC (1대)
* **클라우드 크레딧:**
    * GCP 무료 크레딧 (구체적인 금액 및 기간 확인 필요)
* **클라우드 서빙 예산 (잠정):**
    * AWS 서빙 환경 구축 시 **최대 100만원** 지원 가능 (프로젝트 전체 시스템 예산의 일부).
    * **비용 협의:** 클라우드 파트와 **AI 모델의 온라인 서빙 시간당 비용** 기반으로 예산 협의가 필요합니다. 이를 위해 예상 사용량(호출 빈도, 시간대 등)을 바탕으로 한 시간 단위 비용 모델 수립이 요구됩니다.
    * **주의:** 해당 예산은 전체 시스템에 할당된 것이므로, AI 서빙에 필요한 **상세 스펙(vRAM, CPU/GPU 성능, 필요 TPS 등)을 산정**하고 이를 기반으로 클라우드 파트와 최종 예산을 확정해야 합니다.

## 3. 모델 및 프레임워크 연구/테스트

### 3.1. 이미지 생성 모델

* **초기 고려 모델:** Stable Diffusion 1.5 베이스 모델들을 테스트했으나, 생성 이미지의 품질 면에서 한계 확인.
* **현재 주력 모델:** **Stable Diffusion XL (SDXL)** 베이스 모델. 1.5 대비 월등히 우수한 품질을 보여주므로 해당 모델 기반으로 연구/개발 진행 결정.
* **테스트 결과 및 확인 사항:**
    * 로컬 환경에서 SDXL 모델 로드 및 기본 이미지 생성 가능 확인.
    * **이슈:**
        * **스타일 부적합:** 여전히 뉴스 콘텐츠에 바로 적용하기 어려운 스타일(Anime 등)의 모델이 많음. 뉴스 호환성 높은 스타일(사실적, 일러스트 등) 탐색 필요.
        * **품질 문제:** SD 1.5 대비 개선되었으나, 여전히 프롬프트 및 모델 설정에 따라 얼굴/손가락 등 세부 묘사 오류 발생 가능성 존재. (관련 NFR: NF-QUA-001)
        * **리소스 요구량:** SDXL은 1.5 대비 더 많은 vRAM 및 연산 능력 요구. 로컬(4080 Super) 및 클라우드 환경에서의 효율적 서빙 방안 연구 필요.
* **향후 계획 (TBD):**
    * **[TBD-AI-IMG-01]** 뉴스 콘텐츠에 적합한 SDXL 기반 모델/LoRA/Checkpoint 리서치 및 선정.
    * **[TBD-AI-IMG-02]** SDXL 최적화를 위한 프롬프트 엔지니어링 기법 연구 (스타일 제어, 품질 개선, Negative Prompt 활용 등).
    * **[TBD-AI-IMG-03]** 얼굴/손가락 등 세부 묘사 오류 개선 기법 적용 테스트 (Adetailer, HiRes Fix 등).
    * **[TBD-AI-IMG-04]** 이미지 생성 특강 참여 (참석 완료 가정, 내용 반영 필요 시 업데이트) 및 최신 기법 학습/적용.
    * **[TBD-AI-IMG-05]** 선정된 모델/기법 기반의 상세 서빙 스펙(vRAM, 처리 시간 등) 산정.

### 3.2. LLM (Large Language Model)

* **테스트 진행 모델:**
    * **Llama 3.2 3B:**
        * **결과:** 기본적인 영어 대화 및 지시 수행 능력 확인.
        * **이슈:** 한국어 처리 능력이 매우 미흡함.
    * **LG EXAOne Deep 7.8B:**
        * **결과:** 한국어 특화 모델로 알려졌으나, 실제 테스트 시 영어 답변 품질이 더 우수하며 수학 문제 풀이에 특화된 경향 확인.
        * **이슈:** 뉴스 요약, 시나리오 변환 등 목표 작업에는 부적합.
* **결론:** 현재 시점에서 **한국어 성능이 만족스러운 오픈소스 LLM을 직접 서빙하는 것은 리소스 및 성능 제약으로 현실적인 어려움**이 따름.
* **대안 전략:** **영어 기반 LLM 활용 + 번역 API 연동**
    * 입력(뉴스 기사)을 한국어 -> 영어로 번역.
    * 영어 LLM으로 핵심 작업(요약, 시나리오 생성 등) 수행.
    * 결과를 영어 -> 한국어로 번역.
* **향후 고려 모델/서비스:**
    * **LLM:** Llama 4 등 최신 영어 기반 모델 성능 분석.
    * **번역 API:** **Papago** (일 1만자 무료), Google Translate API 등.
* **향후 계획 (TBD):**
    * **[TBD-AI-LLM-01]** 영어권 LLM (Llama 4 포함) 중 뉴스 처리(요약, 시나리오 변환 등)에 가장 적합한 모델 선정 및 성능 검증.
    * **[TBD-AI-LLM-05]** 번역 API(Papago 우선 검토) 연동 테스트: API 호출 방식, 일일 사용량 제한(Papago 1만자) 관리 방안, 번역 품질이 최종 결과에 미치는 영향 분석, 비용 산정.
    * **[TBD-AI-LLM-04]** 선정된 영어 LLM + 번역 API 파이프라인 기반의 상세 서빙 스펙(LLM 리소스, 번역 API 호출 시간/비용 등) 산정.

### 3.3. AI 에이전트/프레임워크

* **테스트/검토 도구:**
    * **MCP:** 사용 편의성 높으나 외부 API 종속성 강함. 포트폴리오 구성 및 심층 개발에는 한계. 필요시 API 기반 빠른 구현용 옵션.
    * **LangGraph:** 복잡한 워크플로우 기반 AI 에이전트 구축에 유리. 뉴스 처리 -> (번역) -> LLM 처리 -> (번역) -> 이미지 생성 연계 등 자동화에 적합 판단.
* **향후 계획 (TBD):**
    * **[TBD-AI-FRM-01]** **LangGraph**를 활용하여 **번역 API 연동을 포함한** 뉴스 처리 및 이미지 생성 연계 워크플로우 자동화 에이전트 PoC(Proof of Concept) 개발 추진.
    * **[TBD-AI-FRM-02]** LangGraph 구현 복잡성 또는 기능 한계 시, MCP 등 대안 프레임워크 활용 재검토.

## 4. 개발 계획 및 일정

### 4.1. 전체 프로젝트 기간

* 2025년 3월 31일 ~ 2025년 8월 1일

### 4.2. AI 파트 주요 개발 단계 (잠정)

* **1단계: 모델/프레임워크/API 최종 선정 (진행 중 ~ MM월 DD일)**
    * 이미지 모델 선정 및 프롬프트 연구 ([TBD-AI-IMG-01], [TBD-AI-IMG-02])
    * 영어 LLM 선정 및 번역 API 검증 ([TBD-AI-LLM-01], [TBD-AI-LLM-05])
    * LangGraph PoC 개발 ([TBD-AI-FRM-01])
    * 최종 기술 스택 확정
* **2단계: 핵심 기능 개발 (MM월 DD일 ~ MM월 DD일)**
    * 에이전트 워크플로우 상세 구현 (번역 연동 포함)
    * 모델 서빙 API 개발 ([TBD-AI-API-01])
* **3단계: 통합 및 테스트 (MM월 DD일 ~ MM월 DD일)**
    * Backend 시스템과 AI 에이전트/API 연동
    * 기능/성능/품질 테스트 및 안정화 ([TBD-AI-IMG-03], NF-QUA-001/002)
* **4단계: 배포 및 모니터링 (MM월 DD일 ~)**
    * 확정된 환경에 모델 및 에이전트 배포 ([TBD-AI-DEP-01])
    * 운영 모니터링 및 성능/비용 최적화

*AI 파트 상세 일정은 1단계 완료 후 구체화 예정입니다.*

### 4.3. 전체 시스템 인프라 구축 일정 (클라우드 파트 주관, 참고용)

| 기간          | 주요 작업                             |
| :------------ | :------------------------------------ |
| MM/DD ~ MM/DD | 요구사항 분석 및 인프라 설계          |
| MM/DD ~ MM/DD | Terraform 기반 IaC 구현             |
| MM/DD ~ MM/DD | GitHub Actions + CodeDeploy 연동      |
| MM/DD ~ MM/DD | CloudFront + Route 53 구성          |
| MM/DD ~ MM/DD | 모니터링 및 로깅 구축 (CloudWatch 등) |

*위 인프라 일정은 AI 모델 배포 및 운영 환경과 직접적으로 연관되므로, 진행 상황을 주시하고 필요한 협력을 진행해야 합니다.*

## 5. API 정의 (TBD)

AI 에이전트 또는 개별 모델 기능을 호출하기 위한 API 명세를 정의합니다.

* **[TBD-AI-API-01]** LangGraph 에이전트 실행 API 정의 (Input: 뉴스 기사 URL/텍스트, Output: (번역된) 요약 텍스트, 생성된 이미지 URL 등 워크플로우 결과). 내부적으로 번역 API 호출 포함될 수 있음.
* (필요시) 개별 기능 API 정의 (예: SDXL 이미지 생성 전용 API)

*API 명세는 Backend 파트와 협의하여 확정합니다.*

## 6. 배포 환경 및 CI/CD 파이프라인 (TBD)

* **배포 환경:**
    * **[TBD-AI-DEP-01]** 최종 선정된 모델(SDXL, 영어 LLM) 및 에이전트의 **상세 서빙 스펙 산정** 완료 후, 비용(모델 서빙 + 번역 API) 및 성능 고려하여 최적 배포 환경 결정 (AWS EC2 GPU 인스턴스, SageMaker, GCP Vertex AI 등).
    * **[TBD-AI-DEP-02]** AWS 사용 시, 산정된 스펙과 예상 사용량 기반으로 **클라우드 파트와 시간당 비용 협의 및 예산 확정.**
* **CI/CD 파이프라인:**
    * **[TBD-AI-CICD-01]** 모델/코드 변경 시 자동 테스트 및 배포 위한 파이프라인 설계 (Git, Docker, Jenkins/Github Actions, 모델 레지스트리 등 활용).

## 7. 코드 품질 및 컨벤션 (TBD)

* **컨벤션 룰:**
    * **[TBD-AI-CODE-01]** Python PEP 8 준수, 프로젝트 내 명명 규칙, 주석 가이드라인 구체화 및 공유.
* **코드 품질 관리 도구:**
    * **[TBD-AI-CODE-02]** Linter (`Flake8`), Formatter (`Black`) 설정 및 CI 연동.
    * **[TBD-AI-CODE-03]** 코드 리뷰 프로세스 정립 및 수행.

## 8. 트러블슈팅

* **이미지 생성 모델:**
    * **이슈:** SDXL 모델에서 얼굴/손가락 등 세부 묘사 오류 발생 가능성.
    * **진행:** Negative Prompt 강화, Adetailer 등 후처리 확장 기능 테스트 예정 ([TBD-AI-IMG-03]).
* **LLM:**
    * **이슈:** 만족스러운 성능의 한국어 오픈소스 LLM 직접 서빙 어려움 확인.
    * **진행:** 영어 LLM + 번역 API 연동 전략으로 전환. 번역 API(Papago 등) 테스트 및 연동 방안 연구 중 ([TBD-AI-LLM-05]).

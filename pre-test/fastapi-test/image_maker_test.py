"""

í•´ë‹¹ ë‚´ìš©ì€ Colab ì—ì„œ ì‹¤í–‰ë˜ëŠ” ê±¸ ì „ì œë¡œ ë§Œë“¤ì–´ì§

"""

# ğŸ“Œ 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
# !pip install diffusers transformers accelerate safetensors

# ğŸ“Œ 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from diffusers import StableDiffusionXLPipeline, EulerAncestralDiscreteScheduler
import torch
from PIL import Image
import json
import os

# ğŸ“Œ 3. ëª¨ë¸ ë° LoRA ë¡œë“œ
# SDXL ëª¨ë¸ ë¡œë“œ
pipe = StableDiffusionXLPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0",
    torch_dtype=torch.float16,
    variant="fp16",
    use_safetensors=True
)
pipe.to("cuda")

# ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)

# ì§€ë¸Œë¦¬ ìŠ¤íƒ€ì¼ LoRA ë¡œë“œ
pipe.load_lora_weights("ntc-ai/SDXL-LoRA-slider.Studio-Ghibli-style", weight_name="Studio Ghibli style.safetensors", adapter_name="Studio Ghibli style")

# LoRA í™œì„±í™”
pipe.set_adapters(["Studio Ghibli style"], adapter_weights=[2.0])

# ğŸ“Œ 4. ë³€í™˜ëœ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
with open("converted_prompts.json", "r", encoding="utf-8") as f:
    prompts = json.load(f)

# ğŸ“Œ 5. ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥
output_dir = "ghibli_images"
os.makedirs(output_dir, exist_ok=True)

for idx, prompt in enumerate(prompts):
    image = pipe(
        prompt=prompt,
        negative_prompt="nsfw, low quality, blurry",
        width=768,
        height=768,
        guidance_scale=7.5,
        num_inference_steps=30
    ).images[0]
    image.save(os.path.join(output_dir, f"cut_{idx+1}.png"))
    print(f"ì»· {idx+1} ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {os.path.join(output_dir, f'cut_{idx+1}.png')}")

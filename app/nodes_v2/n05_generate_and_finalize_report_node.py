# ai/app/nodes_v2/n05_generate_and_finalize_report_node.py

from __future__ import annotations
import re
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional

import jinja2
from sentence_transformers import SentenceTransformer, util
from rapidfuzz import fuzz

from app.workflows.state_v2 import WorkflowState
from app.utils.logger import get_logger
from app.services.llm_service import LLMService

logger = get_logger(__name__)
NODE_ORDER = 5
MAIN_USE_THRESHOLD = 3
SECONDARY_USE_THRESHOLD = 2
EMB_MODEL = SentenceTransformer("sentence-transformers/distiluse-base-multilingual-cased-v2")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì • (ì´ íŒŒì¼ ê¸°ì¤€ ìƒìœ„ 3ë‹¨ê³„)
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
DEFAULT_RESULTS_BASE_DIR = PROJECT_ROOT / "results"


class N05GenerateAndFinalizeReportNode:
    """
    N05GenerateAndFinalizeReportNode

    â€¢ ëª©ì :
      - N04ì—ì„œ ìˆ˜ì§‘ëœ raw_search_resultsë¥¼ 'ì „ë¬¸ì ì¸ ë³´ê³ ì„œ' ê´€ì ìœ¼ë¡œ í•„í„°ë§
      - í•„í„°ë§ëœ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ 4ì»· ë§Œí‰ ì œì‘ìš© Fact Brief ë³´ê³ ì„œ HTML ìƒì„± ë° ì €ì¥

    â€¢ ìƒì„±ì ì¸ì:
      - llm_service: LLMService ì¸ìŠ¤í„´ìŠ¤ (fact-check ìš©ë„ë¡œ ì‚¬ìš©)
      - results_base_dir: ë³´ê³ ì„œ ì €ì¥ ê¸°ë³¸ ë””ë ‰í† ë¦¬ (ì—†ìœ¼ë©´ PROJECT_ROOT/results ì‚¬ìš©)
    """

    def __init__(self, llm_service: LLMService, results_base_dir: Optional[Path] = None):
        self.llm_service = llm_service
        # Jinja2 í™˜ê²½: í…œí”Œë¦¿ ë¡œë”ë¡œ í•¨ìˆ˜ ë¡œë” ì‚¬ìš© (í…œí”Œë¦¿ ë‚´ìš©ì€ _load_templateì—ì„œ ì •ì˜)
        self.jinja_env = jinja2.Environment(
            loader=jinja2.FunctionLoader(self._load_template),
            autoescape=jinja2.select_autoescape(['html', 'xml'])
        )
        self.template_name = "deep_research_report_template.jinja2"
        # ì €ì¥ ê²½ë¡œ ì„¤ì •: ì£¼ì…ëœ results_base_dir ë˜ëŠ” ê¸°ë³¸ê°’
        self.results_base_dir = results_base_dir or DEFAULT_RESULTS_BASE_DIR
        logger.info(f"N05Initialize: results_base_dir={self.results_base_dir}", extra={"node": "N05", "order": NODE_ORDER})

    # â”€â”€â”€â”€â”€â”€â”€ 1) ì „ë¬¸ì„± ì¤‘ì‹¬ í•„í„°ë§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _filter_report_sources(
        self,
        raw_results: List[Dict[str, Any]],
        issue_summary: str,
        key_aspects: List[str],
        satire_targets: List[str] | None,
        work_id: str
    ) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """
        raw_resultsë¥¼ ìˆœíšŒí•˜ë©° 'ì „ë¬¸ì„±' í•„í„°ë§ì„ ìˆ˜í–‰í•˜ì—¬
        - MAIN_USE_THRESHOLD ì´ìƒ: main_sources
        - SECONDARY_USE_THRESHOLD ì´ìƒ: secondary_sources
        ê·¸ ì™¸: ì œì™¸

        ì ìˆ˜ ì‚°ì •:
          â‘  ì£¼ì œ ìœ ì‚¬ë„ (ë¬¸ì¥ ì„ë² ë”© ì½”ì‚¬ì¸ ìœ ì‚¬ë„ â‰¥ 0.35 â†’ +1)
          â‘¡ URL ë˜ëŠ” ì œëª©/ìŠ¤ë‹ˆí«ì— 'ë³´ê³ ì„œ', 'ë°±ì„œ' ë“± í‚¤ì›Œë“œ â†’ +1
          â‘¢ ìŠ¤ë‹ˆí« ê¸¸ì´ â‰¥ 120ì ë˜ëŠ” transcript ê¸¸ì´ â‰¥ 300ì â†’ +1
          â‘£ ìŠ¤ë‹ˆí«ì— ë‚ ì§œ/ìˆ«ì/í†µê³„ ì§€í‘œ â†’ +1
          â‘¤ satire_targets í‚¤ì›Œë“œê°€ ë³¸ë¬¸ì— í¬í•¨ â†’ +1
          â‘¥ ì œëª© ì¤‘ë³µ ì‹œ ê°ì  -1
          â‘¦ score == 2ì¸ ê²½ìš° LLM fact-check ìˆ˜í–‰(ì„±ê³µ: +1, ì‹¤íŒ¨: -1)
        """
        def _embed(text: str):
            return EMB_MODEL.encode(text, convert_to_tensor=True)

        ref_texts = [issue_summary] + (key_aspects or [])
        ref_vecs = [_embed(t) for t in ref_texts if t]

        def sim_to_refs(text: str) -> float:
            if not ref_vecs:
                return 0.0
            v = _embed(text)
            return float(max(util.cos_sim(v, rv) for rv in ref_vecs)[0][0])

        PDF_PATTERN = re.compile(r'\.pdf$', re.I)
        REPORT_KW = re.compile(
            r'(ë³´ê³ ì„œ|ë°±ì„œ|white\s*paper|policy\s*paper|statistical|annual\s*report|ì—°êµ¬\s*ê²°ê³¼|í†µê³„|ì¡°ì‚¬)',
            re.I
        )
        FACT_REGEX = re.compile(r'\d{4}[-ë…„\.]\d{1,2}|[0-9]{3,}[ ]?(ì–µ|ë§Œ|ì¡°|%|\bpeople\b|\btons\b)', re.I)

        main_use: List[Dict[str, Any]] = []
        secondary_use: List[Dict[str, Any]] = []
        seen_titles: list[str] = []

        async def llm_fact_check(snippet_text: str) -> bool:
            """
            LLMì„ ì´ìš©í•´ ì£¼ì–´ì§„ ìŠ¤ë‹ˆí«ì´ 'ì „ë¬¸ ë³´ê³ ì„œ ìˆ˜ì¤€ì˜ ì‚¬ì‹¤ ì§„ìˆ 'ì¸ì§€ Yes/Noë¡œ ë°˜í™˜.
            """
            prompt = (
                "Answer with a single word 'Yes' or 'No'.\n"
                "Does the following sentence look like an objective, factual statement "
                "found in an official or expert report?\n\n"
                f"\"{snippet_text.strip()[:250]}\""
            )
            rsp = await self.llm_service.generate_text(
                messages=[{"role": "user", "content": prompt}],
                request_id=f"{work_id}_factchk",
                max_tokens=3,
                temperature=0.0
            )
            return rsp.get("generated_text", "").strip().lower().startswith("yes")

        for item in raw_results:
            # None ì•ˆì „í™”: snippet í˜¹ì€ transcriptê°€ Noneì´ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ëŒ€ì²´
            title = item.get("title", "") or ""
            snippet = item.get("snippet") or ""
            transcript = item.get("transcript") or ""
            body_for_sim = f"{title} {snippet}"[:600]

            # â‘  ì£¼ì œ ìœ ì‚¬ë„
            topic_sim = sim_to_refs(body_for_sim)
            score = 1 if topic_sim >= 0.35 else 0

            # â‘¡ 'ì „ë¬¸ ë¬¸ê±´' ì‹ í˜¸: URLì´ PDFì´ê±°ë‚˜, ì œëª©/ìŠ¤ë‹ˆí«ì— ë³´ê³ ì„œ ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨
            url = item.get("url", "") or ""
            if PDF_PATTERN.search(url) or REPORT_KW.search(title) or REPORT_KW.search(snippet):
                score += 1

            # â‘¢ ì •ë³´ ë°€ë„: ìŠ¤ë‹ˆí« ê¸¸ì´ ë˜ëŠ” transcript ê¸¸ì´
            if len(snippet) >= 120 or len(transcript) >= 300:
                score += 1

            # â‘£ íŒ©íŠ¸ ìˆ˜ì¹˜Â·ë‚ ì§œ ì¡´ì¬
            if FACT_REGEX.search(snippet):
                score += 1

            # â‘¤ í’ì ëŒ€ìƒ í‚¤ì›Œë“œ í¬í•¨ â†’ ë³´ì¡° ê°€ì 
            if satire_targets and any(t.lower() in body_for_sim.lower() for t in satire_targets):
                score += 1

            # â‘¥ ì œëª© ì¤‘ë³µ ê°ì 
            if any(fuzz.QRatio(title, existing) > 80 for existing in seen_titles):
                score -= 1
            else:
                seen_titles.append(title)

            # â‘¦ LLM fact-check: score == 2ì¼ ë•Œë§Œ ì‹¤í–‰
            if score == 2:
                try:
                    fact_ok = await llm_fact_check(snippet)
                    score += 1 if fact_ok else -1
                    item["quality_llm_checked"] = True
                except Exception as e:
                    logger.warning(f"[N05] LLM fact-check error: {e}", extra={"work_id": work_id})
                    item["quality_llm_checked"] = False

            # ì ìˆ˜ ë° ì‚¬ìœ  ê¸°ë¡
            item["quality_score"] = score
            item["quality_reason"] = f"sim:{topic_sim:.2f};len:{len(snippet)};score:{score}"

            # ë¶„ë¥˜
            if score >= MAIN_USE_THRESHOLD:
                main_use.append(item)
            elif score >= SECONDARY_USE_THRESHOLD:
                secondary_use.append(item)

        return main_use, secondary_use

    # â”€â”€â”€â”€â”€â”€â”€ 2) Jinja2 í…œí”Œë¦¿ ë¡œë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _load_template(self, template_name: str) -> Optional[str]:
        """
        Jinja2 FunctionLoaderë¥¼ ìœ„í•œ ì½œë°±. í…œí”Œë¦¿ ì´ë¦„ì— í•´ë‹¹í•˜ëŠ” ìŠ¤íŠ¸ë§ì„ ë°˜í™˜.
        ì´ ì˜ˆì‹œì—ì„œëŠ” ì‹¤ì œ íŒŒì¼ ë¡œë”© ëŒ€ì‹  ì¸ë¼ì¸ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
        """
        if template_name != self.template_name:
            return None

        # ê°„ë‹¨í•œ HTML í…œí”Œë¦¿ ì˜ˆì‹œ
        return """
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8" />
            <title>Satirical Comic Fact Brief</title>
            <style>
                body { font-family: Arial, Helvetica, sans-serif; padding: 20px; }
                .sec { margin-bottom: 2em; }
                .card { border: 1px solid #ddd; padding: 1em; margin-bottom: .5em; }
            </style>
        </head>
        <body>
            <h1>ğŸ“‘ Satirical Comic Fact Brief</h1>
            <p><strong>Issue:</strong> {{ issue_summary }}</p>
            <p><strong>Satire Target(s):</strong> {{ satire_targets | join(', ') }}</p>
            <p><strong>Tone Suggestion:</strong> {{ tone_suggestion }}</p>

            <div class="sec">
                <h2>âœ… Core Fact Sources</h2>
                {% for src in main_sources %}
                    <div class="card">
                        <h3>{{ src.title }}</h3>
                        <p>{{ src.snippet }}</p>
                        <p>
                            <small>
                            <a href="{{ src.url }}" target="_blank">{{ src.source_domain }}</a>
                             â€¢ quality {{ src.quality_score }}
                            </small>
                        </p>
                    </div>
                {% endfor %}
            </div>

            {% if secondary_sources %}
            <div class="sec">
                <h2>ğŸ§ Additional References (Need Cross-Check)</h2>
                <ul>
                {% for s in secondary_sources %}
                    <li><a href="{{ s.url }}" target="_blank">{{ s.title }}</a> ({{ s.quality_score }})</li>
                {% endfor %}
                </ul>
            </div>
            {% endif %}
        </body>
        </html>
        """

    # â”€â”€â”€â”€â”€â”€â”€ 3) HTML ë Œë”ë§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _render_html(
        self,
        main_sources: List[Dict[str, Any]],
        secondary_sources: List[Dict[str, Any]],
        issue_summary: str,
        satire_targets: List[str],
        tone_suggestion: str
    ) -> str:
        """
        Jinja2 í…œí”Œë¦¿ì„ ì´ìš©í•´ HTML ë¬¸ìì—´ ìƒì„±.
        """
        template = self.jinja_env.get_template(self.template_name)
        return template.render(
            issue_summary=issue_summary,
            satire_targets=satire_targets or [],
            tone_suggestion=tone_suggestion,
            main_sources=main_sources,
            secondary_sources=secondary_sources
        )

    # â”€â”€â”€â”€â”€â”€â”€ 4) ë³´ê³ ì„œ ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _save_report_to_local_fs(self, report_html_content: str, work_id: str, extra_log: Dict[str, Any]) -> Optional[str]:
        """
        ìƒì„±ëœ HTML ë³´ê³ ì„œë¥¼ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì— ì €ì¥í•©ë‹ˆë‹¤.
        - PROJECT_ROOT/results/<work_id>/generated_report.html ê²½ë¡œë¡œ ì €ì¥
        """
        if not work_id:
            logger.error("Work IDê°€ ëˆ„ë½ë˜ì–´ ë³´ê³ ì„œë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", extra=extra_log)
            return None
        if not report_html_content or not isinstance(report_html_content, str):
            logger.warning("ì €ì¥í•  ë³´ê³ ì„œ ë‚´ìš©ì´ ì—†ê±°ë‚˜ ë¬¸ìì—´ì´ ì•„ë‹™ë‹ˆë‹¤.", extra=extra_log)
            return None

        try:
            # 1) work_id ë””ë ‰í† ë¦¬ ìƒì„±
            report_dir = self.results_base_dir / work_id
            report_dir.mkdir(parents=True, exist_ok=True)

            # 2) íŒŒì¼ ê²½ë¡œ ì„¤ì •
            report_file_path = report_dir / "generated_report.html"

            # 3) íŒŒì¼ ì“°ê¸°
            with open(report_file_path, "w", encoding="utf-8") as f:
                f.write(report_html_content)

            saved_path_str = str(report_file_path.resolve())
            logger.info(f"ë³´ê³ ì„œê°€ ë¡œì»¬ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {saved_path_str}", extra=extra_log)
            return saved_path_str

        except Exception as e:
            logger.error(f"ë³´ê³ ì„œ ë¡œì»¬ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", extra={**extra_log, "exception": str(e)})
            return None

    # â”€â”€â”€â”€â”€â”€â”€ 5) ë…¸ë“œ run() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def run(self, state: WorkflowState) -> Dict[str, Any]:
        meta_sec = state.meta
        search_sec = state.search
        query_ctx = state.query.query_context

        work_id = meta_sec.work_id
        extra_log = {"work_id": work_id, "node": "N05", "order": NODE_ORDER}

        meta_sec.workflow_status[NODE_ORDER] = "PROCESSING"
        logger.info("N05: ì‹œì‘ â€“ ê²°ê³¼ í•„í„°ë§ ë° ë³´ê³ ì„œ ìƒì„±", extra=extra_log)

        raw_results = search_sec.raw_search_results or []
        if not raw_results:
            logger.warning("N05: raw_search_resultsê°€ ë¹„ì–´ ìˆìŒ â€“ ë³´ê³ ì„œ ìƒì„± ìŠ¤í‚µ", extra=extra_log)
            meta_sec.workflow_status[NODE_ORDER] = "COMPLETED"
            return {"meta": meta_sec.model_dump()}

        issue_summary = query_ctx.get("issue_summary_for_comic", "")
        key_aspects = query_ctx.get("key_aspects_to_search", [])
        satire_targets = query_ctx.get("satire_target", [])
        tone_suggestion = query_ctx.get("tone_suggestion", "")

        # 1) í•„í„°ë§: ì „ë¬¸ì„± ê¸°ì¤€ìœ¼ë¡œ main/secondary ë¶„ë¥˜
        main_sources, secondary_sources = await self._filter_report_sources(
            raw_results,
            issue_summary,
            key_aspects,
            satire_targets,
            work_id
        )

        logger.info(
            f"N05: í•„í„° ê²°ê³¼ â€“ main: {len(main_sources)}, secondary: {len(secondary_sources)}",
            extra=extra_log
        )

        # 2) HTML ë Œë”ë§ (Jinja2 í…œí”Œë¦¿ ì‚¬ìš©)
        html_report = self._render_html(
            main_sources, secondary_sources, issue_summary, satire_targets, tone_suggestion
        )

        # 3) ë¡œì»¬ ì €ì¥ (PROJECT_ROOT/results/<work_id>/generated_report.html)
        saved_path = self._save_report_to_local_fs(html_report, work_id, extra_log)
        if not saved_path:
            logger.error("N05: ë³´ê³ ì„œ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", extra=extra_log)

        # 4) state ì—…ë°ì´íŠ¸
        #    - raw_search_resultsì— main + secondaryë¥¼ ë®ì–´ì¨ì„œ ì´í›„ ë…¸ë“œ ë˜ëŠ” ë¦¬í„´ ì‹œ í™œìš©
        search_sec.raw_search_results = main_sources + secondary_sources
        state.report.report_content = html_report
        state.report.saved_report_path = saved_path
        state.report.contextual_summary = issue_summary

        meta_sec.workflow_status[NODE_ORDER] = "COMPLETED"
        logger.info("N05: ì™„ë£Œ â€“ ë‹¤ìŒ ë…¸ë“œë¡œ ì´ë™", extra=extra_log)

        return {
            "meta": meta_sec.model_dump(),
            "search": search_sec.model_dump(),
            "report": state.report.model_dump()
        }

import logging
import json
from typing import Dict, Any, Optional, List
from pydantic import BaseModel, Field
from app.workflows.state import ComicState
from app.services.llm_server_client import call_llm_api

logger = logging.getLogger(__name__)

# 1ï¸âƒ£ LLM ì‘ë‹µì„ ìœ„í•œ ì¶œë ¥ êµ¬ì¡° ì •ì˜ (ëª¨ë‘ ì˜ì–´ë¡œ ì‘ë‹µ)
class ScenarioResponse(BaseModel):
    description: str = Field(..., description="ì§§ì€ ì‹œê° ì¥ë©´ ì„¤ëª… (ì˜ì–´)")
    dialogue: str = Field(..., description="ì§§ì€ ëŒ€ì‚¬ ë˜ëŠ” ì„¤ëª… (ì˜ì–´)")
    prompt: str = Field(..., description="Flux ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ (ìì—°ì–´ ë¬¸ì¥, ì˜ì–´)")

# vLLM guided_json ìš© schema ìƒì„±
scenario_json_schema = ScenarioResponse.model_json_schema()

# 2ï¸âƒ£ few-shot í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° (ì¶œë ¥ í¬í•¨ ì˜ì–´ë¡œ ì‘ì„±ë¨)
# prompt í˜•ì‹ : "[Subject], [Background], [Composition], [Lighting], [Emotional tone or color style]" + [LoRA Style Trigger]
def generate_prompt_template_with_fewshots(humor_text: str) -> str:
    fewshot_1 = '''
Humor: "At a climate summit, no one notices the globe is on fire."

Output:
{
  "description": "A burning globe sits in the middle of the conference table while people talk around it.",
  "dialogue": "Politician: 'That's just a visual effect, nothing to worry about!'",
  "prompt": "A burning globe on the center of a modern conference table, surrounded by politicians in suits, wide angle composition, warm cinematic lighting, surreal and dramatic atmosphere"
}'''

    fewshot_2 = '''
Humor: "A scientist faints after reading a high temperature on a thermometer outside."

Output:
{
  "description": "A sweating scientist stares at a thermometer showing a dangerously high temperature.",
  "dialogue": "Scientist: 'It's rising again? This can't be real!'",
  "prompt": "A stressed scientist holding a thermometer, standing outside a research building, close-up composition, bright midday light, tense and alarming tone"
}'''

    instruction = f"""
You are a professional visual storyteller designing scenes for a comic.

For each humorous situation, generate:

1. A short visual **description** of the scene (1â€“2 sentences, in English).
2. A short **dialogue or caption** (in English).
3. A **Flux 1 Dev style image generation prompt** in natural English â€” a full sentence with visual structure:
   - Include: main subject, background context, composition (e.g., close-up, wide angle), lighting style, emotional tone
   - Do not use key:value pairs. Instead, make it a natural descriptive sentence.
   - Keep the tone visually rich and immersive.

Respond in this strict JSON format:
{{
  "description": "...",
  "dialogue": "...",
  "prompt": "..."
}}

Here are two examples:
{fewshot_1}

{fewshot_2}

Now, write the output in the same format for this scene:

Humor: "{humor_text}"
"""
    return instruction.strip()


# 3ï¸âƒ£ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì—ì´ì „íŠ¸
class ScenarioWriterAgent:
    async def run(self, state: ComicState) -> Dict[str, Any]:
        logger.info("--- [ScenarioWriterAgent] ì‹¤í–‰ ì‹œì‘ ---")
        updates: Dict[str, Any] = {}
        humor_texts: List[str] = state.humor_texts or []

        if not humor_texts:
            logger.warning("[ScenarioWriterAgent] humor_textsê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            updates["scenarios"] = []
            updates["error_message"] = "No humor texts to process."
            return updates

        # ğŸ¯ ì´ì œ styleì€ ì“°ì§€ ì•Šê³  lora_styleë§Œ ì‚¬ìš©
        lora_style = state.lora_style  # Noneì´ë©´ ê·¸ëŒ€ë¡œ ë‘ê³ , ìˆìœ¼ë©´ promptì— ì¶”ê°€

        results = []

        for idx, humor in enumerate(humor_texts):
            prompt = generate_prompt_template_with_fewshots(humor.strip())
            logger.info(f"[ScenarioWriterAgent] ({idx+1}/{len(humor_texts)}) ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì¤‘...")

            try:
                response = await call_llm_api(
                    prompt,
                    max_tokens=512,
                    temperature=0.7,
                    guided_json=scenario_json_schema
                )

                if not response or response.strip() == "":
                    raise ValueError("LLM ì‘ë‹µì´ ë¹„ì–´ ìˆìŒ")

                parsed = json.loads(response)

                required = {"description", "dialogue", "prompt"}
                if not required.issubset(parsed):
                    raise ValueError(f"ì‘ë‹µì— í•„ìˆ˜ í‚¤ ëˆ„ë½: {parsed.keys()}")

                # ğŸ‘‰ ìŠ¤íƒ€ì¼ ì¶”ê°€: lora_styleë§Œ ì‚¬ìš©
                if lora_style:
                    parsed["prompt"] = f"{parsed['prompt'].strip()}, {lora_style}"

                results.append(parsed)

            except Exception as e:
                logger.error(f"[ScenarioWriterAgent] humor[{idx}] ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                results.append({
                    "description": "[ERROR]",
                    "dialogue": "[ERROR]",
                    "prompt": "[ERROR]"
                })

        updates["scenarios"] = results
        updates["error_message"] = None
        logger.info("--- [ScenarioWriterAgent] ì‹¤í–‰ ì¢…ë£Œ ---")
        return updates
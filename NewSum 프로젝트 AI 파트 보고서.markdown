# NewSum 프로젝트 AI 파트 보고서 (PL 미팅용)

**작성일**: 2025년 4월 16일\
**수신**: AI 파트 PL\
**발신**: AI 파트 (Logan, William)

**주요 내용**: 현재 AI 파트 진행 상황, 주요 성과, 식별된 이슈 및 향후 계획 공유

---

## 1. 개요 및 현황 요약

NewSum 프로젝트 AI 파트의 목표(뉴스용 이미지 생성, 텍스트 처리) 달성을 위해 모델 연구/개발을 진행 중입니다. 제공해주신 위키(v1.3 / 250408) 내용을 기반으로, 최근 다음과 같은 주요 진척 사항 및 결정 사항이 있었습니다.

- **API 통합**: 풀스택 담당자와 협의하여, AI 기능 호출을 단일 이미지 요청 API로 표준화하기로 결정했습니다. 이는 향후 시스템 연동 복잡성을 줄일 것으로 기대됩니다.
- **이미지 생성 (Logan)**: Stable Diffusion XL(SDXL) 기반 LoRA 파인튜닝 및 이미지 생성 테스트를 완료하여 특정 스타일에 맞는 이미지 생성 가능성을 확인했습니다. 다만, 프롬프트 준수성(특히 인물 묘사) 관련 이슈가 발견되어 추가 테스트 및 개선 작업이 필요합니다.
- **LLM (William)**: Llama 3.2 3B 모델 파인튜닝 및 Colab 기반 서빙/터널링(cloudflared) 테스트에 성공했습니다. 이를 통해 개발/테스트 단계에서 외부 클라우드 비용을 절감할 수 있는 잠재적 방안을 확보했습니다. Llama 4는 확인했으나, 현재 기능 구현에는 3.2 모델로도 가능하다고 판단하여 우선순위를 조정했습니다.
- **주요 지연/보류 사항**: LangGraph 기반 에이전트 워크플로우 설계/PoC 개발은 다른 작업 우선순위로 인해 아직 착수하지 못했습니다. 뉴스 스크래핑 기술 연구 등 신규 R&D 필요 영역도 식별되었습니다.

---

## 2. 세부 진행 상황

### 2.1. 이미지 생성 모델 (담당: Logan)

- **기존 상황 (Wiki 기반)**: SD 1.5 한계 확인 후 SDXL 기반으로 연구 전환. 뉴스 적합 스타일 탐색, 품질(얼굴/손가락 오류), 리소스 요구량 이슈 인지. (\[TBD-AI-IMG-01\] \~ \[TBD-AI-IMG-05\])
- **최근 진행**:
  - 특정 이미지 스타일에 맞춰 SDXL 모델을 학습시킨 LoRA 파일 생성 및 이를 활용한 이미지 생성 테스트 완료.
  - **이슈 발견**: 특정 프롬프트(예: "사람을 그려달라")에도 불구하고 LoRA 학습 데이터 특성(배경 위주) 때문인지 인물이 그려지지 않는 등, 프롬프트 내용을 정확히 반영하지 못하는 경우 발생. (NF-QUA-001 연관)
- **향후 계획**:
  - 프롬프트 엔지니어링 강화 (\[TBD-AI-IMG-02\]) 및 LoRA 학습 데이터/방식 개선을 통해 프롬프트 준수성 및 결과 일반화 능력 향상 연구 지속. 다양한 스타일에 대응 가능한 LoRA 구성 방안 모색.
  - 얼굴/손가락 등 세부 묘사 오류 개선 기법 적용 테스트 (\[TBD-AI-IMG-03\]).
  - SDXL 모델을 Colab 환경에서 최적으로 서빙하고 외부에서 접근 가능하도록 터널링하는 작업 진행 필요. (LLM 파트 성공 사례 참고)
  - 최종 모델/기법 기반 상세 서빙 스펙 산정 (\[TBD-AI-IMG-05\]).

### 2.2. LLM (담당: William)

- **기존 상황 (Wiki 기반)**: 한국어 오픈소스 LLM 직접 서빙의 어려움으로 '영어 LLM + 번역 API' 전략 채택. Llama 4 등 최신 모델 분석 및 Papago 등 번역 API 연동 테스트 필요 (\[TBD-AI-LLM-01\], \[TBD-AI-LLM-05\]).
- **최근 진행**:
  - Llama 4 출시 확인했으나, 현재 뉴스 요약/시나리오 생성 기능 구현에는 Llama 3.2 3B 모델로도 충분하다고 잠정 판단. (추가 검토는 후순위)
  - Colab 활용 모델 서빙 최적화 집중:
    - Llama 3.2 3B 모델을 mlabonne/FineTome-100k 등 데이터셋으로 파인튜닝 완료.
    - Unsloth, vLLM 라이브러리 적용하여 Colab 환경에서 추론 속도 개선.
    - cloudflared를 이용한 터널링 성공: Colab에서 실행 중인 LLM 모델 API를 외부 시스템(로컬 PC 등)에서 호출 가능함 확인.
  - **의의 및 한계**: Colab 기반 서빙은 개발/테스트 단계에서 클라우드 비용 절감에 크게 기여할 수 있으나, 안정성, 확장성, 지속 운영 가능성 측면에서는 여전히 검증이 필요합니다. (현재도 일부 불안정 요소 존재)
- **향후 계획**:
  - 번역 API(Papago 우선) 연동 테스트 및 일일 사용량(1만자) 관리 방안, 번역 품질 영향 분석, 비용 산정 (\[TBD-AI-LLM-05\]).
  - 선정된 영어 LLM + 번역 API 파이프라인 기반 상세 서빙 스펙 산정 (\[TBD-AI-LLM-04\]).
  - Colab 서빙 방식의 안정성 추가 검증 및 이슈 해결.

### 2.3. AI 에이전트/프레임워크 (LangGraph)

- **기존 상황 (Wiki 기반)**: 복잡한 워크플로우(번역-LLM-번역-이미지 생성 등) 자동화에 LangGraph가 적합하다고 판단. PoC 개발 계획 (\[TBD-AI-FRM-01\]).
- **현재 상황**:
  - 미착수: 이미지/LLM 모델 연구 및 Colab 서빙 테스트 우선 진행으로 LangGraph 구조 설계 및 PoC 개발 시작하지 못함.
- **향후 계획**: 빠른 시일 내 LangGraph를 활용한 에이전트 워크플로우 상세 설계 및 PoC 개발 착수 필요. (\[TBD-AI-FRM-01\] 우선순위 상향 필요)

### 2.4. API 정의

- **결정 사항**: 풀스택 파트와 협의 완료. Backend에서 AI 기능을 호출하는 인터페이스는 \*\*단일 API (이미지 생성 요청)\*\*로 정의. 내부적으로 필요한 LLM 호출, 번역, 이미지 생성 등은 AI 에이전트(LangGraph 기반 예상) 또는 내부 로직으로 처리 예정. (\[TBD-AI-API-01\] 방향 확정)

### 2.5. 배포 환경 및 CI/CD

- **탐색**: Colab 기반 서빙/터널링 방식을 테스트 단계에서 활용 가능성 확인.
- **과제**:
  - 정식 배포 환경 연구: 안정적인 서비스 운영을 위해 GCP, AWS 등 클라우드 환경에서의 모델 배포 방안 (EC2 GPU, SageMaker, Vertex AI 등) 심층 연구 필요 (\[TBD-AI-DEP-01\]).
  - 비용 협의: 최종 모델(SDXL, LLM) 및 에이전트의 상세 스펙 산정 후, 예상 사용량 기반 시간당 비용 모델 수립 및 클라우드 파트와 AWS 예산(최대 100만원) 내 운영 가능 여부 협의 필요 (\[TBD-AI-DEP-02\]).
  - CI/CD 파이프라인 설계 (\[TBD-AI-CICD-01\]).

### 2.6. 신규 R&D 및 기타 과제

- **뉴스 스크래핑**: 외부 뉴스 콘텐츠 확보 방안 연구 필요.
  - 검색 엔진 테스트: Naver, Daum, Google Custom Search, Tavily, Bing 등 효율적인 뉴스 소스 탐색.
  - 스크래핑 방식 테스트: Selenium, Scrapy, RSS 피드, Reddit API 등 기술 검토 및 안정적인 데이터 수집 방안 마련.
- **최적화**: 모델 추론 성능(속도, 리소스 사용량) 최적화 방안 마련.
- **아키텍처**: 서비스 아키텍처 모듈화 방안 마련 (향후 확장성 고려).
- **코드 품질/컨벤션**: 관련 TBD 항목(\[TBD-AI-CODE-01\] \~ \[TBD-AI-CODE-03\]) 구체화 필요.

---

## 3. 이슈 및 위험 요소 (사전 검토 필요 사항)

- **SDXL LoRA 품질**: 학습된 LoRA가 특정 프롬프트를 무시하는 현상은 이미지 생성 결과의 신뢰성을 저해할 수 있습니다. 개선 방안 마련 및 충분한 테스트가 요구됩니다.
- **Colab 서빙의 지속성**: Colab Pro+ 환경은 비용 효율적일 수 있으나, 세션 유지, 성능 변동성, 장기적 안정 운영 측면에서 한계가 명확합니다. 테스트 단계를 넘어선 활용 가능성에 대한 신중한 검토 및 대안(클라우드 배포) 준비가 필수적입니다.
- **LangGraph 개발 지연**: 에이전트 워크플로우 개발 지연은 전체 기능 통합 및 자동화 일정에 영향을 줄 수 있습니다. 조속한 착수가 필요합니다.
- **뉴스 스크래핑 불확실성**: 안정적이고 합법적인 뉴스 데이터 확보 방안이 확정되지 않으면 핵심 기능 개발에 차질이 생길 수 있습니다. 관련 R&D 리소스 투입 결정이 필요합니다.
- **예산 제약**: 확정된 클라우드 예산(최대 100만원) 내에서 SDXL, LLM 모델의 안정적인 서빙(GPU 인스턴스 비용 등) 및 번역 API 비용 충당이 가능할지 면밀한 예측 및 관리가 필요합니다. 특히 SDXL의 리소스 요구량이 높을 수 있습니다.
- **번역 API 제약**: Papago 무료 티어(일 1만자)는 실제 서비스 운영 시 부족할 수 있습니다. 유료 전환 시 비용 문제 및 다른 API(Google Translate 등) 고려 필요성이 발생할 수 있습니다.

---

## 4. 논의/결정 필요 사항 (PL 미팅)

- **우선순위 조정**: LangGraph PoC 개발, SDXL LoRA 개선, 뉴스 스크래핑 R&D 등 산적한 과제들의 우선순위 재확인 및 리소스 배분 논의.
- **Colab 활용 전략**: 개발/테스트 단계 외 실제 운영 환경에서의 Colab 활용 가능성 및 한계점 논의. 정식 클라우드 배포 계획 구체화 시점 결정.
- **SDXL LoRA 품질 이슈 대응 방안 검토 및 승인**.
- **뉴스 스크래핑 R&D 진행 여부 및 방식 결정**.
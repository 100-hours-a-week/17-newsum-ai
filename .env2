# -----------------------------------------------------------------------------
# .env 환경 변수 설정 파일 (샘플)
# -----------------------------------------------------------------------------
# 사용법:
# 1. 이 파일의 복사본을 프로젝트 루트 디렉토리에 '.env' 이름으로 생성합니다.
# 2. 아래 설정 값들, 특히 API 키 및 비밀 값들을 실제 환경에 맞게 채워넣습니다.
# 3. 필요에 따라 선택적 파라미터들을 조정합니다.
# 4. 실제 비밀 정보가 포함된 '.env' 파일은 절대로 버전 관리 시스템(Git 등)에 커밋하지 마세요!
# -----------------------------------------------------------------------------

# =============================================================================
# 섹션 1: 필수 설정 (Essential Configuration)
# =============================================================================
# 애플리케이션의 핵심 기능 또는 특정 활성화된 기능(아래 플래그 참조)을 위해
# 반드시 설정해야 하는 값들입니다. 사용하는 외부 서비스의 API 키/자격증명을 입력하세요.


# --- 번역 API (Naver Papago) ---
# TRANSLATION_ENABLED=true 설정 시 필요합니다.
NAVER_CLIENT_ID=I9lJ7iTgVVuKaHTc7dS9          # 필수 (번역 사용 시): Naver Cloud Platform Client ID
NAVER_CLIENT_SECRET=LTwnXNPAU5      # 필수 (번역 사용 시): Naver Cloud Platform Client Secret

# --- 검색 / 소셜 미디어 / 트렌드 도구 API ---
# 사용하는 각 도구에 대한 API 키/자격 증명이 필요합니다.
# Google Search (Custom Search API & YouTube Data API)
GOOGLE_API_KEY=AIzaSyAaS2qiThOYB6GgtTmamWqzuAqriAQXdJI            # 필수 (Google Search 또는 YouTube 사용 시)
GOOGLE_CSE_ID=e408de3d4f5df4459             # 필수 (Google Search 사용 시): Google Custom Search Engine ID
YOUTUBE_API_KEY=${GOOGLE_API_KEY}                  # 필수 (YouTube 사용 시): 기본값으로 GOOGLE_API_KEY 사용. 필요시 별도 키 지정 가능.

# Twitter API v2
TWITTER_BEARER_TOKEN=AAAAAAAAAAAAAAAAAAAAAH730wEAAAAATTVJuoSeKyizmKgBpSsLRVsquwQ%3DBsnWlDo4l8QMFul5fQYzqRK5ZaQjL3SWFaiAzIIQVgnOJylIjK # 필수 (Twitter 사용 시)

# Reddit API
REDDIT_CLIENT_ID=gwWkFh_ugwqHW-ZgN1qiew # 필수 (Reddit 사용 시): Reddit App Client ID (스크립트 타입 앱)
REDDIT_CLIENT_SECRET=ISzd5aRAaqjSHjoztV-uD0J5Cyk8mA # 필수 (Reddit 사용 시): Reddit App Client Secret
REDDIT_USERNAME=VirtualWelcome5998  # 선택적: Reddit 스크립트 인증 방식 사용 시
REDDIT_PASSWORD=nzDYc/fhfT7LgJa # 선택적: Reddit 스크립트 인증 방식 사용 시 (보안 주의!)
# Reddit
REDDIT_USER_AGENT=script:NewsumApp:v1.0 (by u/${REDDIT_USERNAME})   # Reddit API 사용 시 User Agent (변경 권장)
REDDIT_TARGET_SUBREDDITS=news,worldnews,technology,science,futurology,korea,AskReddit,datascience,artificial # 의견 수집 대상 서브레딧 (쉼표 구분)
REDDIT_OPINION_MAX_RESULTS=15               # Reddit에서 수집할 최대 의견(댓글) 수

# --- 캐싱 / 데이터베이스 (Redis) ---
# 캐싱 및 일부 데이터 저장에 Redis 사용 시 필요합니다.
REDIS_HOST=localhost                               # 권장: 운영 환경에서는 실제 Redis 호스트 주소로 변경
REDIS_PORT=6379                                    # 선택적: Redis 기본 포트 (변경 시 설정)
# REDIS_PASSWORD=                                 # 선택적: Redis 비밀번호가 설정된 경우 입력
REDIS_DB=0                                         # 선택적: 사용할 Redis 데이터베이스 번호 (기본값: 0)
REDIS_URL=redis://${REDIS_HOST}:${REDIS_PORT}/${REDIS_DB}


# --- LangGraph 체크포인터 (Redis) ---
# LangGraph 워크플로우 상태 저장을 위한 Redis 연결 URL
# export REDIS_URL="redis://localhost:6379/0" 해당 내용을 반드시 환경변수로 지정해 줘야 함 python 내부 설정
# 단순 Redis가 아닌 redis-stack 설치 필요 (설치 방법)
# jammy(Ubuntu 22.04) 기반 저장소로 다시 설정
# echo "deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb jammy main" | sudo tee /etc/apt/sources.list.d/redis.list
# sudo apt-get update
# sudo apt-get install redis-stack
# which redis-stack-server
# redis-stack-server --version
# redis-cli MODULE LIST

# --- 저장소 (AWS S3 & Local Fallback) ---
# UPLOAD_TO_S3=true 설정 시 AWS S3 관련 정보가 필요합니다.
S3_BUCKET_NAME=your-s3-bucket-name              # 필수 (S3 업로드 사용 시): 대상 S3 버킷 이름
AWS_REGION=your-aws-region                      # 필수 (S3 업로드 사용 시): 대상 S3 버킷의 AWS 리전 (예: ap-northeast-2)
# AWS_ACCESS_KEY_ID=                              # 선택적: IAM 역할/프로파일 대신 사용할 경우 AWS Access Key ID
# AWS_SECRET_ACCESS_KEY=                           # 선택적: IAM 역할/프로파일 대신 사용할 경우 AWS Secret Access Key
LOCAL_STORAGE_PATH=                             # 선택적: S3 연결 실패 또는 비활성화 시 사용할 로컬 저장 경로 (기본값: <프로젝트루트>/storage/local_fallback)

# --- 웹 스크래핑 프록시 ---
# SCRAPER_USE_PROXY=true 설정 시 필요합니다.
# SCRAPER_PROXY_URL=http://user:password@proxy.example.com:port # 예시: 사용자 인증이 필요한 프록시

# --- LangSmith (Optional Observability) ---
# LangSmith 추적 기능을 사용하려면 설정하세요.
# LANGCHAIN_API_KEY=YOUR_LANGCHAIN_API_KEY_HERE     # 필수 (LangSmith 사용 시)
# LANGCHAIN_PROJECT=ComicGenerator-Project          # 선택적: LangSmith 프로젝트 이름 (기본값 있음)
# LANGCHAIN_TRACING_V2=true                       # 필수 (LangSmith 사용 시): LangSmith 추적 활성화 (LangChain 라이브러리가 직접 읽음)
# LANGCHAIN_ENDPOINT=https://api.smith.langchain.com # 선택적: LangSmith 엔드포인트 (기본값 있음)


# =============================================================================
# 섹션 2: 코어 설정 및 기능 활성화 플래그 (Core Settings & Feature Flags)
# =============================================================================
# 애플리케이션의 기본적인 동작 모드나 주요 기능의 활성화 여부를 제어합니다. (true/false)

PROJECT_NAME=Newsum                 # 선택적: 프로젝트 이름 (로깅, LangSmith 등에 사용될 수 있음)
DEBUG=True                                 # 선택적: 디버그 모드 활성화 (상세 로그 출력 등)
TRANSLATION_ENABLED=false                   # 만화 텍스트 등 번역 기능 활성화 여부 (Naver API 키 필요)
UPLOAD_TO_S3=false                          # 최종 결과물(만화 이미지 등) S3 업로드 활성화 여부 (AWS S3 설정 필요)
SAVE_AGENT_RESULTS=True                     # 각 단계(에이전트/노드)의 결과 데이터 저장 여부
SAVE_AGENT_INPUTS=False                     # 각 단계의 입력 데이터 저장 여부
SAVE_DEBUG_INFO=True                        # 상세 디버깅 정보 저장 여부 (결과 폴더 내)
SCRAPER_USE_PROXY=false                     # 웹 스크래핑 시 프록시 사용 여부 (프록시 URL 설정 필요)


# =============================================================================
# 섹션 3: 튜닝 가능 파라미터 (Tunable Parameters)
# =============================================================================
# 대부분 기본값이 코드(settings.py)에 정의되어 있으며, 필요에 따라 성능, 비용, 결과 품질 등을
# 튜닝하기 위해 여기서 값을 덮어쓸 수 있습니다.

# --- 일반 도구 / API 호출 기본값 ---
TOOL_RETRY_ATTEMPTS=3                       # 외부 도구 API 호출 기본 재시도 횟수
TOOL_RETRY_WAIT_MIN=1                       # 재시도 시 최소 대기 시간 (초)
TOOL_RETRY_WAIT_MAX=10                      # 재시도 시 최대 대기 시간 (초)
TOOL_HTTP_TIMEOUT=15                        # 외부 도구 API 호출 기본 타임아웃 (초)
# --- 언어 모델 (LLM) API ---
# LLM_API_KEY=                 # 필수: LLM 서비스 인증 키 (예: OpenAI API Key)
LLM_API_ENDPOINT=http://0.0.0.0:8000/v1/chat/completions # 필수: LLM 엔드포인트 사용 설정 (예: http://localhost:11434/v1)

# --- LLM 동작 튜닝 ---
LLM_API_TIMEOUT=60                          # LLM API 호출 타임아웃 (초)
LLM_API_RETRIES=3                           # LLM API 호출 재시도 횟수
DEFAULT_LLM_MODEL=unsloth/Llama-3.2-3B-Instruct #/content/drive/MyDrive/unsloth_models/Llama_3.2_3B_test/lora_model # Llama3.2 기본 사용할 LLM 모델 ID
# 작업 유형별 LLM Temperature (0.0 ~ 1.0, 낮을수록 결정적, 높을수록 창의적)
DEFAULT_CACHE_TTL_TOPIC=30
DEFAULT_KEYWORD_CONF_THRESHOLD=0.6
LLM_TEMPERATURE_ANALYSIS=0.2
LLM_TEMPERATURE_EXTRACT=0.1
LLM_TEMPERATURE_SUMMARIZE=0.3
LLM_TEMPERATURE_QA_GEN=0.1
LLM_TEMPERATURE_QA_VERIFY=0.0
LLM_TEMPERATURE_STANCE=0.1
LLM_TEMPERATURE_SENTIMENT=0.1
LLM_TEMPERATURE_OPINION_SUMMARIZE=0.4
LLM_TEMPERATURE_SYNTHESIS=0.5
LLM_TEMPERATURE_CREATIVE=0.7                # 아이디어/스토리 생성 등 창의적 작업
LLM_TEMPERATURE_SCENARIO=0.7                # 만화 시나리오 생성 (기본값: creative와 동일)
LLM_TEMPERATURE_SCENARIO_EVAL=0.3           # 생성된 시나리오 평가
# 작업 유형별 최대 토큰 수 (결과 길이 및 비용 제한)
MAX_TOKENS_EXTRACT=512
MAX_TOKENS_SUMMARIZE=300
MAX_TOKENS_QA_GEN=512
MAX_TOKENS_QA_VERIFY=100
MAX_TOKENS_STANCE=10
MAX_TOKENS_SENTIMENT=10
MAX_TOKENS_OPINION_SUMMARIZE=400
MAX_TOKENS_SYNTHESIS=300
MAX_TOKENS_IDEA=1024
MAX_TOKENS_SCENARIO=2048
MAX_TOKENS_SCENARIO_EVAL=512

# --- 이미지 생성 API ---
# 이미지 생성 기능을 사용하려면 아래 값들을 설정해야 합니다.
IMAGE_SERVER_URL=        # 필수 (이미지 생성 시): 이미지 생성 서버 주소 (예: Stability AI, DALL-E API 등)
#IMAGE_SERVER_API_TOKEN= # 필수 (이미지 생성 시): 해당 서버 인증 토큰/키
# --- 이미지 생성 동작 튜닝 ---
DEFAULT_IMAGE_MODEL=dall-e-3                # 기본 사용할 이미지 생성 모델 ID
IMAGE_DEFAULT_STYLE="4-panel comic style, simple illustration, clear lines, vibrant colors" # 기본 이미지 스타일 프롬프트
MAX_IMAGE_PROMPT_LEN=500                    # 이미지 생성 프롬프트 최대 길이 제한
IMAGE_HEIGHT=1024                           # 생성 이미지 높이 (픽셀)
IMAGE_WIDTH=1024                            # 생성 이미지 너비 (픽셀)
IMAGE_NEGATIVE_PROMPT="text, letters, words, signature, watermark, ugly, deformed, blurry, low quality, multiple panels" # 이미지 생성 시 제외할 요소
# IMAGE_STYLE_PRESET=                      # 선택적: 사용하는 이미지 API가 지원하는 스타일 프리셋 (예: 'cinematic')
IMAGE_API_RETRIES=3                         # 이미지 생성 API 재시도 횟수 (기본값: LLM 재시도 횟수와 동일)
IMAGE_DOWNLOAD_RETRIES=3                    # 생성된 이미지 다운로드 재시도 횟수

# --- 번역 동작 튜닝 ---
TARGET_TRANSLATION_LANGUAGE=en              # 번역 목표 언어 코드 (예: ko, ja, zh-CN)
# SOURCE_LANGUAGE=                         # 번역 소스 언어 코드 (미지정 시 자동 감지 시도)
TRANSLATOR_CONCURRENCY=3                    # 번역 작업 동시 실행 수

# --- 검색 / 소셜 미디어 / 트렌드 도구 동작 튜닝 ---
# Google Search
Google_Search_API_RETRIES=3                 # Google Search API 전용 재시도 횟수 (기본값: 일반 도구 재시도 횟수)
SEARCH_RESULT_COUNT=10                      # 검색 API 호출 시 요청할 기본 결과 수
TARGET_URLS_PER_KEYWORD=5                   # 키워드 당 수집할 목표 URL 수 (Google Search 등 활용 시)
# Google Trends (PyTrends)
# --- 트렌드 분석 가중치 (선택적, 기본값 제공됨) ---
# 각 소스별 가중치 합계가 1.0이 되도록 설정하는 것을 권장합니다.
# TREND_GOOGLE_WEIGHT=0.6
# TREND_TWITTER_WEIGHT=0.4
# TREND_REDDIT_WEIGHT=0.0
PYTRENDS_TIMEFRAME=now 7-d                # Google Trends 조회 기간 (예: 'now 1-d', 'today 3-m')
PYTRENDS_GEO=                              # Google Trends 지역 필터 (예: 'US', 'KR', 비워두면 전세계)
PYTRENDS_HL=en-US                           # Google Trends 인터페이스 언어
PYTRENDS_BATCH_DELAY_SEC=1.5                # Pytrends 요청 간 지연 시간 (초)
# Twitter
TWITTER_COUNTS_DELAY_SEC=5                # Twitter API 요청 간 지연 시간 (초)
TWITTER_OPINION_MAX_RESULTS=15              # Twitter에서 수집할 최대 의견(트윗) 수
# YouTube
YOUTUBE_OPINION_MAX_RESULTS=25              # YouTube에서 수집할 최대 의견(댓글) 수 (API 할당량 주의)
# Blog / Community Search (via Google)
BLOG_OPINION_MAX_RESULTS=10                 # 블로그 검색 결과에서 수집할 최대 의견 수
COMMUNITY_OPINION_MAX_RESULTS=10            # 커뮤니티 검색 결과에서 수집할 최대 의견 수
TARGET_COMMUNITY_DOMAINS=dcinside.com,clien.net,ruliweb.com,fmkorea.com,theqoo.net,instiz.net,etoland.co.kr,ppomppu.co.kr,82cook.com,quora.com,stackoverflow.com # 의견 수집 대상 커뮤니티 도메인 목록
# RSS Feeds
# PREDEFINED_RSS_FEEDS=http://example.com/rss1.xml,http://sample.org/feed.rss # 기본 RSS 피드 외 추가/대체할 피드 목록 (쉼표 구분, settings.py 기본값 있음)

# --- 웹 스크래핑 동작 튜닝 ---
SCRAPER_USER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 # 스크래핑 시 사용할 User Agent
SCRAPER_HTTP_TIMEOUT=20                     # 스크래핑 HTTP 요청 타임아웃 (초)
SCRAPER_CONCURRENCY=5                       # 뉴스 기사 등 본문 스크래핑 동시 실행 수
OPINION_SCRAPER_CONCURRENCY=3               # 댓글 등 의견 스크래핑 동시 실행 수
SCRAPER_MIN_DELAY_MS=1500                   # 스크래핑 요청 사이 최소 지연 시간 (밀리초)
SCRAPER_MAX_DELAY_MS=4000                   # 스크래핑 요청 사이 최대 지연 시간 (밀리초)
SCRAPER_ROTATE_UA=false                     # User Agent 로테이션 사용 여부
# Selenium (동적 콘텐츠 스크래핑)
# SELENIUM_GRID_URL=http://localhost:4444/wd/hub # Selenium Grid 사용 시 Hub URL
SELENIUM_HEADLESS=True                      # Selenium 브라우저 Headless 모드 실행 여부
SELENIUM_RETRY_ATTEMPTS=2                   # Selenium 작업 재시도 횟수
SELENIUM_RETRY_WAIT_SECONDS=1               # Selenium 재시도 간 대기 시간 (초)

# --- 데이터 처리 및 정제 튜닝 ---
TRUSTED_NEWS_DOMAINS=news.kbs.co.kr,news.sbs.co.kr,yna.co.kr,chosun.com,joongang.co.kr,donga.com,hani.co.kr,khan.co.kr,bbc.com,cnn.com,nytimes.com,reuters.com,apnews.com,bloomberg.com,wsj.com # 신뢰할 수 있는 뉴스 출처 도메인 목록
MAX_ARTICLES_TO_SCRAPE=5                    # URL 당 스크랩할 최대 뉴스 기사 수 (동일 도메인 내 링크 등)
MIN_EXTRACTED_TEXT_LENGTH=100               # 유효한 텍스트로 간주할 최소 길이 (스크랩 후)
MIN_LANGDETECT_TEXT_LENGTH=50               # 언어 감지를 위한 최소 텍스트 길이
LANGUAGE_FILTER=en,ko                       # 처리할 텍스트의 허용 언어 코드 목록 (쉼표 구분)
# 스팸 필터링
SPAM_KEYWORDS=buy now,click here,order now,special offer,limited time,discount,free,cheap,amazing,winner,prize,cash,casino,lottery,viagra,pharmacy,subscribe,loan,credit,mortgage,debt,investment,earn money,make money,weight loss,diet,guaranteed,100%,$$$ # 스팸 간주 키워드
SPAM_MAX_URL_COUNT=2                        # 스팸 간주 최대 URL 포함 개수
SPAM_MAX_UPPERCASE_RATIO=0.5                # 스팸 간주 최대 대문자 비율
# 중복 제거 (Simhash)
SIMHASH_THRESHOLD=3                         # Simhash 유사도 임계값 (해밍 거리, 낮을수록 유사)
SIMHASH_TOKEN_WIDTH=64                      # Simhash 비트 수 (64 또는 128)
# 의견 수집 목표치
MAX_TOTAL_OPINIONS_TARGET=60                # 모든 플랫폼에서 수집/처리할 최대 의견 수 목표치
# 플랫폼별 최대/최소 의견 샘플링 수 (JSON 형식, 문자열 내 큰따옴표 사용 주의!)
MAX_OPINIONS_PER_PLATFORM_SAMPLING={"Twitter": 15, "Reddit": 15, "YouTube": 10, "Blog": 10, "Community": 10}
MIN_OPINIONS_PER_PLATFORM_SAMPLING={"Twitter": 2, "Reddit": 2, "YouTube": 1, "Blog": 2, "Community": 2}
# 군집화 (KMeans/TF-IDF)
KMEANS_DEFAULT_CLUSTERS=5                   # KMeans 기본 클러스터 수
KMEANS_MIN_SAMPLES=10                       # KMeans 클러스터링 위한 최소 샘플(문서) 수
TFIDF_MAX_FEATURES=5000                     # TF-IDF 벡터화 시 최대 피처(단어) 수
TFIDF_STOP_WORDS=english                    # TF-IDF 불용어 처리 ('english' 또는 None)
TFIDF_MIN_DF=2                              # TF-IDF 단어 최소 문서 등장 빈도
TFIDF_MAX_DF=0.90                           # TF-IDF 단어 최대 문서 등장 비율
TFIDF_NGRAM_RANGE_MIN=1                     # TF-IDF N-gram 범위 최소값 (1: unigram)
TFIDF_NGRAM_RANGE_MAX=2                     # TF-IDF N-gram 범위 최대값 (2: unigram, bigram)
KMEANS_N_INIT=10                            # KMeans 초기 중심점 시도 횟수
KMEANS_MAX_NO_IMPROVEMENT=20                # KMeans 조기 종료 조건 (개선 없을 시 최대 반복 횟수)

# --- 평가 및 의사결정 기준 튜닝 ---
FEQA_THRESHOLD=0.5                          # FEQA (Faithfulness, Error, Quality Assessment) 평가 임계값
# 요약/생성 결과 평가 지표별 임계값 (JSON 형식)
EVALUATION_THRESHOLDS={"rouge_l": 0.3, "bert_score": 0.7, "topic_coverage": 0.6}
# 재시도 또는 대체 경로 결정을 위한 평가 임계값 (JSON 형식)
DECISION_LOGIC_THRESHOLDS={"very_low_rouge": 0.1, "very_low_bertscore": 0.5, "very_low_coverage": 0.3, "low_coverage_high_metrics": 0.7}
BERTSCORE_LANG=en                           # BertScore 계산 시 사용할 언어 모델 ('en', 'ko' 등)

# --- 요약 및 창의적 작업 튜닝 ---
SUMMARIZER_CONCURRENCY=3                    # 병렬 요약 작업 실행 수

# --- 보고서 및 최종 결과물 생성 튜닝 ---
TRENDS_REPORT_TOP_N=3                       # 트렌드 보고서에 포함할 상위 N개 키워드/항목
# 최종 만화 이미지 생성 관련
FINAL_IMAGE_FORMAT=WEBP                     # 최종 만화 이미지 저장 포맷 (WEBP, PNG, JPEG 등)
FINAL_IMAGE_WIDTH=1024                      # 최종 만화 이미지 너비 (픽셀, 리사이징될 수 있음)
FINAL_IMAGE_QUALITY=85                      # 최종 만화 이미지 저장 품질 (WEBP/JPEG 형식, 1-100)
TEXT_OVERLAY_FONT_SIZE_RATIO=20             # 이미지 높이 대비 텍스트 크기 비율 (1/N)
TEXT_OVERLAY_COLOR=black                    # 만화 텍스트 오버레이 색상 이름 또는 hex 코드
MAX_ALT_TEXT_LEN=300                        # 생성할 대체 텍스트(Alt text) 최대 길이


# =============================================================================
# 섹션 4: 경로 설정 (Path Settings)
# =============================================================================
# 애플리케이션이 사용하는 파일 및 디렉토리 경로입니다.
# 기본값은 settings.py에 정의되어 있으며, 필요시 여기서 변경할 수 있습니다.

# RESULTS_DIR=                              # 각 단계 결과 및 디버그 정보 저장 경로 (기본값: <프로젝트루트>/results)
# IMAGE_STORAGE_PATH=                       # 생성된 중간 이미지 저장 경로 (기본값: <프로젝트루트>/storage/images)
# FINAL_COMIC_SAVE_DIR=                     # 최종 만화 파일 저장 경로 (기본값: <프로젝트루트>/final_comics)
# TEMPLATE_DIR=                             # 보고서 생성 등에 사용될 템플릿 파일 경로 (기본값: <프로젝트루트>/app/templates)
# DEFAULT_FONT_PATH=                        # 만화 텍스트 오버레이에 사용할 폰트 파일 경로 (미지정 시 시스템 기본 폰트 시도)

# =============================================================================
# (참고) 기타 설정
# =============================================================================
# InitializeNode 등 코드 내부에서 직접 참조될 수 있는 추가 설정값들.
# 필요시 .env 에 추가하고 settings.py 에서 로드하도록 구현 가능.
# 예: MAX_ARTICLE_TEXT_LEN=10000, MAX_OPINION_TEXT_LEN=2000 등